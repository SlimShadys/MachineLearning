{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scarano Gianmarco - Matricola Code: 2047315"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import needed libraries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Colab compatibility\n",
    "Run this next cell only if you're using Google Colab!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library for downloading files from GoogleDrive. It will be used for downloading the LEGO Dataset.\n",
    "!pip install -U gdown efficientnet wandb --quiet  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuing the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set the global variable for Google Colab, so we can assign paths, etc. accordingly\n",
    "try:\n",
    "  import google.colab\n",
    "  RunningInCOLAB = True\n",
    "except:\n",
    "  RunningInCOLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import efficientnet.keras as efn\n",
    "import gdown\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import activations, losses, optimizers, regularizers\n",
    "from keras.layers import (Activation, AveragePooling2D, BatchNormalization,\n",
    "                          Conv2D, Dense, Dropout, Flatten,\n",
    "                          GlobalAveragePooling2D, Input, MaxPooling2D)\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import load_img\n",
    "from keras.utils.layer_utils import count_params\n",
    "from PIL import Image, ImageOps\n",
    "from sklearn.metrics import (ConfusionMatrixDisplay, classification_report,\n",
    "                             confusion_matrix)\n",
    "from tqdm import tqdm\n",
    "from wandb.keras import WandbCallback, WandbModelCheckpoint\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.10.1\n",
      "tf.Keras version 2.10.0\n",
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow version %s\" %tf.__version__)\n",
    "print(\"tf.Keras version %s\" %tf.keras.__version__)\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WANDB Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B version: 0.13.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mslimshadys\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(F\"W&B version: {wandb.__version__}\")\n",
    "wandb.login()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This method delete useless models from the WANDB servers,\n",
    "after passing the run_id parameter.\n",
    "\n",
    "With useless models, we mean all the models saved up\n",
    "to epoch n and all the best models saved up to epoch n.\n",
    "\n",
    ":param run_id: It's the ID of the run (13qvc9uo, 83cvs1ff, etc.)\n",
    ":param entity: The entity for the WANDB project\n",
    ":param project_name: The name of the WANDB project\n",
    "\n",
    ":return: Delete Artifacts and returns\n",
    "\"\"\" \n",
    "def deleteArtifacts(run_id='None', entity='None', project_name='None'):\n",
    "    \n",
    "    if run_id == 'None' or entity == 'None' or project_name == 'None':\n",
    "        raise NotImplementedError(\"Check parameters! You should provide a run_ID, an entity name and a project name!\")\n",
    "    \n",
    "    modelList = []\n",
    "    runModelList = []\n",
    "    runValList = []\n",
    "    maxModel = 0\n",
    "    maxRunVal = 0\n",
    "    maxRunModel = 0\n",
    "    c = 0\n",
    "\n",
    "    # Get the instance of the given run_id.\n",
    "    run = wandb.Api().run(F\"{entity}/{project_name}/{run_id}\")\n",
    "    \n",
    "    print(F\"Trying to delete useless artifacts from run ID: '{run_id}' ..\")\n",
    "    \n",
    "    # We loop through the artifacts of the given run_id.\n",
    "    # We want to delete artifacts which start with\n",
    "    # - \"model-\"\n",
    "    # - \"run_{run_id}_model\"\n",
    "    # - \"run-{run_id}-validation\"\n",
    "    #\n",
    "    # There might be some more names while looping through the artifacts,\n",
    "    # but our runs just save these \"aliases\".\n",
    "    for artifact_version in run.logged_artifacts():\n",
    "        if(artifact_version.name.startswith(\"model-\")):\n",
    "            modelList.append([artifact_version.name, (artifact_version.name.split(\":\")[1]).replace(\"v\",\"\")])\n",
    "        elif(artifact_version.name.startswith(F\"run_{run_id}_model\")):\n",
    "            runModelList.append([artifact_version.name, (artifact_version.name.split(\":\")[1]).replace(\"v\",\"\")])\n",
    "        elif artifact_version.name.startswith(F\"run-{run_id}-validation\"):\n",
    "            runValList.append([artifact_version.name, (artifact_version.name.split(\":\")[1]).replace(\"v\",\"\")])\n",
    "        else:\n",
    "            raise NotImplementedError(\"Unexpected artifact name!\")\n",
    "\n",
    "    # Check if there\n",
    "    if(len(modelList) > 0):\n",
    "        maxModel = max(int(l[1]) for l in modelList)\n",
    "        \n",
    "    if(len(runModelList) > 0):        \n",
    "        maxRunModel = max(int(l[1]) for l in runModelList)\n",
    "    \n",
    "    if(len(runValList) > 0):\n",
    "        maxRunVal = max(int(l[1]) for l in runValList)\n",
    "        \n",
    "    # Actual deleting iteration. We loop once again and\n",
    "    # we delete all models up to maxModel / maxRunModel, etc.\n",
    "    if(not (maxRunModel == 0 and maxModel == 0)):\n",
    "        for artifact_version in run.logged_artifacts():\n",
    "            if artifact_version.name.startswith(\"model-\"):\n",
    "                nModel = (artifact_version.name.split(\":\")[1]).replace(\"v\",\"\")\n",
    "                if(int(nModel) < maxModel):\n",
    "                    artifact_version.delete(delete_aliases=True)\n",
    "                    c += 1 \n",
    "            elif artifact_version.name.startswith(F\"run_{run_id}_model\"):\n",
    "                runModel = (artifact_version.name.split(\":\")[1]).replace(\"v\",\"\")\n",
    "                if(int(runModel) < maxRunModel):\n",
    "                    artifact_version.delete(delete_aliases=True)\n",
    "                    c += 1\n",
    "            elif artifact_version.name.startswith(F\"run-{run_id}-validation\"):\n",
    "                # We leave the validation artifacts for now.\n",
    "                # We save them into an array, but we do not touch them.\n",
    "                continue\n",
    "            else:\n",
    "                raise NotImplementedError(\"Does this artifact exist?\")\n",
    "            \n",
    "        print(F\"Successfully deleted {str(c)} useless artifacts from {run_id}!\")\n",
    "    else:\n",
    "        print(\"There was nothing to delete.\")\n",
    "        print(F\"N. of model-: {maxModel}\")\n",
    "        print(F\"N. of run_{run_id}_model: {maxRunModel}\")\n",
    "        print(F\"N. of run-{run_id}-validation: {maxRunVal}\")\n",
    "    wandb.finish()\n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config changer in real-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This method edits a configuration parameter given a run_id.\n",
    "\n",
    ":param run_id: It's the ID of the run (13qvc9uo, 83cvs1ff, etc.)\n",
    ":param entity: The entity for the WANDB project\n",
    ":param project_name: The name of the WANDB project\n",
    ":param parameter: The name of the parameter to change\n",
    ":param newValue: The value to give to the parameter passed above\n",
    "\n",
    ":return: Edit the needed parameter and returns\n",
    "\"\"\" \n",
    "def configChanger(run_id='None', entity='None', project_name='None', parameter='None', newValue = 'None'):\n",
    "    \n",
    "    if run_id == 'None' or entity == 'None' or project_name == 'None' or parameter == 'None' or newValue == 'None':\n",
    "        raise NotImplementedError(\"Check parameters! You should provide:\\n- run_ID\\n- Entity name\\n- Project name\\n- Parameter\\n- New Value\")\n",
    "      \n",
    "    run = wandb.Api().run(F\"{entity}/{project_name}/{run_id}\")\n",
    "    \n",
    "    # EXAMPLE: We edit the model_name parameter \n",
    "    run.config[parameter] = newValue\n",
    "\n",
    "    run.update()\n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resuming a run and a checkpoint for continuing the training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This method resumes a run and a model for continuing training.\n",
    "\n",
    ":param project_name: The name of the WANDB project\n",
    ":param entity_name: The entity for the WANDB project\n",
    ":param run_id: It's the ID of the run (13qvc9uo, 83cvs1ff, etc.)\n",
    ":param version: Version for that specific model (v10, v25, etc.)\n",
    ":param configRun: Config for that run\n",
    "\n",
    ":return: Resumes the run and the model and returns\n",
    "\"\"\" \n",
    "def resumeTraining(project_name='None', entity_name='None', run_id='None', version='None', configRun=None):\n",
    "    \n",
    "    if run_id == 'None' or entity_name == 'None' or project_name == 'None' or version == 'None' or configRun == None:\n",
    "        raise NotImplementedError(\"Check parameters! You should provide: \\\n",
    "                                  \\n- run_ID \\\n",
    "                                  \\n- Entity name \\\n",
    "                                  \\n- Project name \\\n",
    "                                  \\n- Version (of the model) \\\n",
    "                                  \\n- configRun (configurations)\")\n",
    "\n",
    "    ## RESUMING A RUN AND A MODEL FOR CONTINUING EPOCHS\n",
    "    wandb.finish()\n",
    "    run = wandb.init(project = project_name, \n",
    "                     entity = entity_name,\n",
    "                     id = run_id,\n",
    "                     job_type = 'train',\n",
    "                     resume = True,\n",
    "    )\n",
    "\n",
    "    artifact = run.use_artifact(F'{entity_name}/{project_name}/run_{run_id}:{version}', type='model')\n",
    "    artifact_dir = artifact.download()\n",
    "    if(RunningInCOLAB):\n",
    "        model = load_model(F\"artifacts/run_{run_id}_model:{version}/files\\\\model-{configRun['model_name']}-{configRun['epochs']}.h5\")\n",
    "    else:\n",
    "        model = load_model(F\"artifacts/run_{run_id}_model-{version}/files/model-{configRun['model_name']}-{configRun['epochs']}.h5\")\n",
    "    \n",
    "    return model, run"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resuming a run and retrieve the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This method resumes a run and retrieves the best model for that run.\n",
    "\n",
    ":param project_name: The name of the WANDB project\n",
    ":param entity_name: The entity for the WANDB project\n",
    ":param run_id: It's the ID of the run (13qvc9uo, 83cvs1ff, etc.)\n",
    "\n",
    ":return: Resumes the run and the best model and returns it\n",
    "\"\"\" \n",
    "def resumeBestModel(project_name='None', entity_name='None', run_id='None'):\n",
    "    \n",
    "    if run_id == 'None' or entity_name == 'None' or project_name == 'None':\n",
    "        raise NotImplementedError(\"Check parameters! You should provide: \\\n",
    "                                    \\n- run_ID \\\n",
    "                                    \\n- Entity name \\\n",
    "                                    \\n- Project name\")\n",
    "    wandb.finish()\n",
    "    \n",
    "    run = wandb.init(project = project_name, \n",
    "                        entity = entity_name,\n",
    "                        id = run_id,\n",
    "                        job_type = 'train',\n",
    "                        resume = True,\n",
    "    )\n",
    "\n",
    "    best_model = wandb.restore('model-best.h5', run_path=F\"{entity_name}/{project_name}/{run_id}\")\n",
    "    model = load_model(best_model.name)\n",
    "    model.summary()\n",
    "        \n",
    "    wandb.finish()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probably the dataset has already been cleaned up.\n",
      "Re-downloading ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1b7WubxZUj0n-OQC6qb0r-iqZrHAiFu1T&export=download&confirm=t\n",
      "To: c:\\Users\\Gianmarco\\Documents\\Git\\MachineLearning\\test\\Homeworks\\2. Image Classification\\LEGODataset.zip\n",
      "100%|██████████| 1.07G/1.07G [03:25<00:00, 5.22MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting dataset...\n",
      "\n",
      "Cleaning files ...\n"
     ]
    }
   ],
   "source": [
    "# We use the library gdown in order to download our LEGODataset from Google Drive.\n",
    "# If downloadDataset = True, it will first clean up the directories and start downloading the dataset\n",
    "# If downloadDataset = False, assumes that the dataset has already been downloaded\n",
    "downloadDataset = True\n",
    "datasetDirectory = \"LEGODataset/\"\n",
    "\n",
    "if downloadDataset:\n",
    "    try:\n",
    "        shutil.rmtree(os.path.join(datasetDirectory))\n",
    "        os.remove(\"LEGODataset.zip\")\n",
    "    except:\n",
    "        print(\"Probably the dataset has already been cleaned up.\")\n",
    "        print(\"Re-downloading ...\")\n",
    "\n",
    "    LEGO_Dataset_URL = 'https://drive.google.com/uc?id=' + '1b7WubxZUj0n-OQC6qb0r-iqZrHAiFu1T' + '&export=download&confirm=t' \n",
    "    gdown.download(LEGO_Dataset_URL, 'LEGODataset.zip', quiet=False)\n",
    "    print(\"\\nExtracting dataset...\")\n",
    "    shutil.unpack_archive(\"LEGODataset.zip\", datasetDirectory)\n",
    "\n",
    "    # Cleaning files\n",
    "    print(\"\\nCleaning files ...\")\n",
    "\n",
    "    os.remove(\"LEGODataset.zip\")\n",
    "    shutil.rmtree(os.path.join(datasetDirectory,\"Collada models\"))\n",
    "    shutil.rmtree(os.path.join(datasetDirectory,\"LEGO brick images v1\"))\n",
    "else:\n",
    "    print(\"Dataset already downloaded.\\nIf you want to re-download it, set the 'downloadDataset' variable to True!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transferring our Dataset into a Pandas DataFrame"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entire Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We enter the dataset directory and for every picture we store:\n",
    "# - 'Image'  = Actual RGB image (400 x 400) as a PIL object\n",
    "# - 'Path'   = Path for that specific Image\n",
    "# - 'ID'     = ID of the brick for that specific Image (080L, 080R, etc.)\n",
    "# - 'Name'   = Name of the brick for that specific Image (flat tile corner 2x2, etc.)\n",
    "# - 'Class'  = Class of the brick for that specific Image (14719, 15672, 18654)\n",
    "images = os.listdir(os.path.join(datasetDirectory,\"dataset\"))\n",
    "\n",
    "rows_list = []\n",
    "dict = {}\n",
    "\n",
    "for img in images:\n",
    "    brick = img.split(\" \")\n",
    "    \n",
    "    brickID = brick[-1].split(\".\")[0]\n",
    "    brickClass = brick[0]\n",
    "    brickName = \" \".join(brick[1:-1])\n",
    "    \n",
    "    dict = {}\n",
    "    dict.update([('Path', os.path.join(datasetDirectory,\"dataset\", img)),('ID', brickID), ('Name', brickName), ('Class', brickClass)]) \n",
    "    rows_list.append(dict)\n",
    "    \n",
    "df = pd.DataFrame(rows_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We enter the dataset directory and for every picture in the validation text file we store:\n",
    "# - 'Image'  = Actual RGB image (400 x 400) as a PIL object\n",
    "# - 'Path'   = Path for that specific Image\n",
    "# - 'ID'     = ID of the brick for that specific Image (080L, 080R, etc.)\n",
    "# - 'Name'   = Name of the brick for that specific Image (flat tile corner 2x2, etc.)\n",
    "# - 'Class'  = Class of the brick for that specific Image (14719, 15672, 18654)\n",
    "#\n",
    "# TODO: We can simply extract the images directly from the DataFrame \"df\".\n",
    "rows_list = []\n",
    "dict = {}\n",
    "rawData = pd.read_csv(os.path.join(datasetDirectory,\"validation.txt\"), index_col=False, header=None)\n",
    "\n",
    "for index, row in rawData.iterrows():\n",
    "\n",
    "    brick = row[0].split(\" \")\n",
    "    \n",
    "    brickID = brick[-1].split(\".\")[0]\n",
    "    brickClass = brick[0]\n",
    "    brickName = \" \".join(brick[1:-1])\n",
    "    \n",
    "    dict = {}\n",
    "    dict.update([('Path', os.path.join(datasetDirectory,\"dataset\", row[0])), ('ID', brickID), ('Name', brickName), ('Class', brickClass)]) \n",
    "    rows_list.append(dict)\n",
    "    \n",
    "dfValidation = pd.DataFrame(rows_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We retrieve the Train dataFrame by simply removing the validation set from the entire set.\n",
    "dfTrain = pd.concat([df,dfValidation], axis=0, ignore_index=True).drop_duplicates(subset=[\"ID\",\"Name\",\"Class\"],keep=False, ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WANB Table for Training/Test set<br>\n",
    "This process takes around 30 mins, since it has to store them into the WANDB server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new W&B run\n",
    "run = wandb.init(\n",
    "    project=\"ML - Homework 2\", \n",
    "    entity=\"slimshadys\"\n",
    ")\n",
    "\n",
    "trainLen = len(dfTrain)    # 3200\n",
    "valLen = len(dfValidation) # 800\n",
    "\n",
    "# Intialize a W&B Artifacts\n",
    "ds = wandb.Artifact(\"LEGODataset\", \"dataset\")\n",
    "\n",
    "# Initialize an empty table\n",
    "columns=[\"Image\", \"Path\", \"ID\", \"Name\", \"Class\"]\n",
    "train_table = wandb.Table(columns=columns)\n",
    "validation_table = wandb.Table(columns=columns)\n",
    "\n",
    "print(F\"Need to fetch {trainLen} training images..\")\n",
    "for index, row in tqdm(dfTrain.iterrows()):\n",
    "    if (index >= trainLen):\n",
    "        break\n",
    "    train_table.add_data(wandb.Image(row['Image']), row['Path'], row['ID'], row['Name'], row['Class'])\n",
    "print(\"--------------------------------------\")\n",
    "\n",
    "print(F\"Need to fetch {valLen} validation images..\")\n",
    "for index, row in tqdm(dfValidation.iterrows()):\n",
    "    if (index >= valLen):\n",
    "        break\n",
    "    validation_table.add_data(wandb.Image(row['Image']), row['Path'], row['ID'], row['Name'], row['Class'])\n",
    "print(\"--------------------------------------\")\n",
    "\n",
    "# Add the table to the Artifact\n",
    "ds['Train_data'] = train_table\n",
    "ds['Validation_data'] = validation_table\n",
    "\n",
    "# Save the dataset as an Artifact\n",
    "ds.save()\n",
    "\n",
    "wandb.log({'Train_data': train_table})\n",
    "wandb.log({'Validation_data': validation_table})\n",
    "\n",
    "# Finish the run\n",
    "run.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating DataLoaders"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the parameters of the training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resetDefaultConfigs():\n",
    "    _ = {}\n",
    "    _.update([\n",
    "        ('data_flag', 'LEGODataset'),\n",
    "        ('batch_size', 32),\n",
    "        ('pretrain_weights', 'imagenet'),\n",
    "        ('epochs', 50),\n",
    "        ('init_learning_rate', 0.001),\n",
    "        ('lr_decay_rate', 0.1),\n",
    "        ('optimizer', 'adam'),\n",
    "        ('model_name', ''),\n",
    "        ('loss_fn', 'categorical_crossentropy'),\n",
    "        ('metrics', [\"accuracy\"]),\n",
    "        ('patience', 5),\n",
    "        ('dataAugmentation', 1)\n",
    "    ])\n",
    "    return _\n",
    "    \n",
    "configs = resetDefaultConfigs()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation / pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataGenerator(value):\n",
    "    if(value == 0):\n",
    "        return ImageDataGenerator(\n",
    "            rescale = 1. / 255\n",
    "        )\n",
    "    elif(value == 1):\n",
    "        return ImageDataGenerator(\n",
    "            rescale = 1. / 255,\\\n",
    "            zoom_range = 0.1,\\\n",
    "            rotation_range = 5\n",
    "        )\n",
    "    elif (value == 2):\n",
    "        return ImageDataGenerator(\n",
    "            rescale = 1. / 255,\\\n",
    "            zoom_range = 0.1,\\\n",
    "            rotation_range = 40, \\\n",
    "            horizontal_flip = 0.3, \\\n",
    "            width_shift_range=0.2, \\\n",
    "            height_shift_range=0.1, \\\n",
    "            vertical_flip = 0.2\n",
    "    )\n",
    "    else:\n",
    "        raise NotImplementedError(\"Please specify a input value for transformations!\\n \\\n",
    "                                  Use:\\n \\\n",
    "                                    \\t- value = 0 (Low image pre-processing)\\n \\\n",
    "                                    \\t- value = 1 (Mid image pre-processing)\\n \\\n",
    "                                    \\t- value = 2 (High image pre-processing)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32000 validated image filenames belonging to 50 classes.\n",
      "Found 8000 validated image filenames belonging to 50 classes.\n",
      "------------------------------------\n",
      "Image size: (200, 200, 3)\n",
      "Number of samples: 32000\n",
      "Number of classes: 50\n",
      "Classes: ['14719', '15672', '18654', '2357', '2420', '2780', '27925', '3001', '3002', '3003', '3004', '3005', '3010', '3020', '3021', '3022', '3023', '3024', '3037', '3038', '3039', '3040', '3045', '3046', '3062', '3063', '3068', '3069', '3070', '3298', '33909', '3622', '3623', '3659', '3675', '3700', '3794', '4150', '41677', '41678', '4274', '4286', '43093', '43857', '4490', '54200', '6143', '6632', '85984', '99301']\n"
     ]
    }
   ],
   "source": [
    "# 0 = Low pre-processing    (Rescaling)\n",
    "# 1 = Mid pre-processing    (Rescaling, Zoom range, Rotation range)\n",
    "# 2 = High pre-processing   (Rescaling, Zoom range, Rotation range, Horizontal Flip, Width shift range, Height shift range, Vertical flip)\n",
    "data_generator = getDataGenerator(configs['dataAugmentation'])\n",
    "\n",
    "# Create a train loader using the data from our Train DataFrame\n",
    "train_loader = data_generator.flow_from_dataframe(\n",
    "    dataframe = dfTrain,                # DataFrame containing the training data\n",
    "    x_col = \"Path\",                     # Column containing the absolute paths to the images\n",
    "    y_col = \"Class\",                    # Column containing the class labels for the images\n",
    "    color_mode = \"rgb\",                 # We can specify \"greyscale\" for 1 channel / \"rgb\" for 3 channels\n",
    "    class_mode = \"categorical\",         # We want a 2D numpy array of one-hot encoded labels\n",
    "    target_size = (200, 200),           # The size of the images. Here we resize our images from (400,400) to (200,200)\n",
    "    batch_size = configs['batch_size'], # Batch size\n",
    "    shuffle = True,                     # We shuffle the train data before generating batches\n",
    ")\n",
    "\n",
    "# For the validation set, we just rescale the single pixels of the images between 0 and 1.\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = 1. / 255)\n",
    "\n",
    "# create a train loader using the data from the DataFrame\n",
    "validation_loader = test_datagen.flow_from_dataframe(\n",
    "    dataframe = dfValidation,           # DataFrame containing the validation data\n",
    "    x_col = \"Path\",                     # Column containing the absolute paths to the images\n",
    "    y_col = \"Class\",                    # Column containing the class labels for the images\n",
    "    color_mode = \"rgb\",                 # We can specify \"greyscale\" for 1 channel / \"rgb\" for 3 channels\n",
    "    class_mode = \"categorical\",         # We want a 2D numpy array of one-hot encoded labels\n",
    "    target_size = (200, 200),           # The size of the images. Here we resize our images from (400,400) to (200,200)\n",
    "    batch_size = configs['batch_size'], # Batch size\n",
    "    shuffle = False,                    # We don't want to shuffle the validation data before generating batches\n",
    ")\n",
    "\n",
    "num_samples = train_loader.n\n",
    "num_classes = len(train_loader.class_indices)\n",
    "input_shape = train_loader.image_shape\n",
    "\n",
    "classnames = [k for k,v in train_loader.class_indices.items()]\n",
    "\n",
    "print(\"------------------------------------\")\n",
    "print(F\"Image size: {str(input_shape)}\")\n",
    "print(F\"Number of samples: {num_samples}\")\n",
    "print(F\"Number of classes: {num_classes}\")\n",
    "print(F\"Classes: {classnames}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show a simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x,y = train_loader.next()\n",
    "\n",
    "image = x[0]\n",
    "label = y[0].argmax()  # categorical from one-hot-encoding\n",
    "plt.title(F\"Class: {classnames[label]} / [{label}]\")\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WANB Table for Augmented Images in the training set<br>\n",
    "This process takes around 30 mins, since it has to store them into the WANDB server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Gianmarco\\Università-Git\\MachineLearning\\test\\Homeworks\\2. Image Classification\\wandb\\run-20221227_192027-1d47fkou</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href=\"https://wandb.ai/slimshadys/ML%20-%20Homework%202/runs/1d47fkou\" target=\"_blank\">magic-feather-8</a></strong> to <a href=\"https://wandb.ai/slimshadys/ML%20-%20Homework%202\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">magic-feather-8</strong>: <a href=\"https://wandb.ai/slimshadys/ML%20-%20Homework%202/runs/1d47fkou\" target=\"_blank\">https://wandb.ai/slimshadys/ML%20-%20Homework%202/runs/1d47fkou</a><br/>Synced 2 W&B file(s), 1 media file(s), 65 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221227_192027-1d47fkou\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize a new W&B run\n",
    "run = wandb.init(project=\"ML - Homework 2\", \n",
    "                    entity=\"slimshadys\",\n",
    "                    id = '1d47fkou',\n",
    "                    resume = True,\n",
    ")\n",
    "\n",
    "# Use the already logged dataset\n",
    "x, y = next(train_loader)\n",
    "images = (dfTrain['Image'][train_loader.index_array])[:32]\n",
    "names = (dfTrain['Name'][train_loader.index_array])[:32]\n",
    "classes = (dfTrain['Class'][train_loader.index_array])[:32]\n",
    "\n",
    "# Create augmentation table\n",
    "augment_table = wandb.Table(columns=['Image', 'Augmented', 'Name', 'Class'])\n",
    "\n",
    "# Get augmented images and log it onto the table\n",
    "for img, x_, name, label in zip(images, x, names, classes):\n",
    "    augment_table.add_data(wandb.Image(img),\n",
    "                           wandb.Image(x_),\n",
    "                           name,\n",
    "                           label,\n",
    "    )\n",
    "\n",
    "# Log the table\n",
    "wandb.log({'Augmented_data_v2': augment_table})\n",
    "\n",
    "# Finish the run\n",
    "run.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define some global variables needed for all the models\n",
    "\n",
    "# - Input Tensor\n",
    "input0 = Input(shape=input_shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Model: \"MobileNetV2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_14 (InputLayer)          [(None, 200, 200, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)                 (None, 100, 100, 32  864         ['input_14[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalization)  (None, 100, 100, 32  128         ['Conv1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)              (None, 100, 100, 32  0           ['bn_Conv1[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (Depth  (None, 100, 100, 32  288        ['Conv1_relu[0][0]']             \n",
      " wiseConv2D)                    )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN (Ba  (None, 100, 100, 32  128        ['expanded_conv_depthwise[0][0]']\n",
      " tchNormalization)              )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_relu (  (None, 100, 100, 32  0          ['expanded_conv_depthwise_BN[0][0\n",
      " ReLU)                          )                                ]']                              \n",
      "                                                                                                  \n",
      " expanded_conv_project (Conv2D)  (None, 100, 100, 16  512        ['expanded_conv_depthwise_relu[0]\n",
      "                                )                                [0]']                            \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (Batc  (None, 100, 100, 16  64         ['expanded_conv_project[0][0]']  \n",
      " hNormalization)                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)        (None, 100, 100, 96  1536        ['expanded_conv_project_BN[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNormal  (None, 100, 100, 96  384        ['block_1_expand[0][0]']         \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)     (None, 100, 100, 96  0           ['block_1_expand_BN[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D)    (None, 101, 101, 96  0           ['block_1_expand_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_depthwise (DepthwiseCo  (None, 50, 50, 96)  864         ['block_1_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (BatchNor  (None, 50, 50, 96)  384         ['block_1_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (ReLU)  (None, 50, 50, 96)   0           ['block_1_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)       (None, 50, 50, 24)   2304        ['block_1_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchNorma  (None, 50, 50, 24)  96          ['block_1_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)        (None, 50, 50, 144)  3456        ['block_1_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNormal  (None, 50, 50, 144)  576        ['block_2_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)     (None, 50, 50, 144)  0           ['block_2_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_2_depthwise (DepthwiseCo  (None, 50, 50, 144)  1296       ['block_2_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (BatchNor  (None, 50, 50, 144)  576        ['block_2_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (ReLU)  (None, 50, 50, 144)  0           ['block_2_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)       (None, 50, 50, 24)   3456        ['block_2_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchNorma  (None, 50, 50, 24)  96          ['block_2_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_add (Add)              (None, 50, 50, 24)   0           ['block_1_project_BN[0][0]',     \n",
      "                                                                  'block_2_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)        (None, 50, 50, 144)  3456        ['block_2_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNormal  (None, 50, 50, 144)  576        ['block_3_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_3_expand_relu (ReLU)     (None, 50, 50, 144)  0           ['block_3_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D)    (None, 51, 51, 144)  0           ['block_3_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_3_depthwise (DepthwiseCo  (None, 25, 25, 144)  1296       ['block_3_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (BatchNor  (None, 25, 25, 144)  576        ['block_3_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (ReLU)  (None, 25, 25, 144)  0           ['block_3_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)       (None, 25, 25, 32)   4608        ['block_3_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchNorma  (None, 25, 25, 32)  128         ['block_3_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)        (None, 25, 25, 192)  6144        ['block_3_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNormal  (None, 25, 25, 192)  768        ['block_4_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)     (None, 25, 25, 192)  0           ['block_4_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_4_depthwise (DepthwiseCo  (None, 25, 25, 192)  1728       ['block_4_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (BatchNor  (None, 25, 25, 192)  768        ['block_4_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (ReLU)  (None, 25, 25, 192)  0           ['block_4_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)       (None, 25, 25, 32)   6144        ['block_4_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchNorma  (None, 25, 25, 32)  128         ['block_4_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_add (Add)              (None, 25, 25, 32)   0           ['block_3_project_BN[0][0]',     \n",
      "                                                                  'block_4_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)        (None, 25, 25, 192)  6144        ['block_4_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNormal  (None, 25, 25, 192)  768        ['block_5_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)     (None, 25, 25, 192)  0           ['block_5_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_5_depthwise (DepthwiseCo  (None, 25, 25, 192)  1728       ['block_5_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (BatchNor  (None, 25, 25, 192)  768        ['block_5_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (ReLU)  (None, 25, 25, 192)  0           ['block_5_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)       (None, 25, 25, 32)   6144        ['block_5_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchNorma  (None, 25, 25, 32)  128         ['block_5_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_add (Add)              (None, 25, 25, 32)   0           ['block_4_add[0][0]',            \n",
      "                                                                  'block_5_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)        (None, 25, 25, 192)  6144        ['block_5_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNormal  (None, 25, 25, 192)  768        ['block_6_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)     (None, 25, 25, 192)  0           ['block_6_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D)    (None, 27, 27, 192)  0           ['block_6_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_6_depthwise (DepthwiseCo  (None, 13, 13, 192)  1728       ['block_6_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (BatchNor  (None, 13, 13, 192)  768        ['block_6_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (ReLU)  (None, 13, 13, 192)  0           ['block_6_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)       (None, 13, 13, 64)   12288       ['block_6_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_6_project_BN (BatchNorma  (None, 13, 13, 64)  256         ['block_6_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)        (None, 13, 13, 384)  24576       ['block_6_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNormal  (None, 13, 13, 384)  1536       ['block_7_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)     (None, 13, 13, 384)  0           ['block_7_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_7_depthwise (DepthwiseCo  (None, 13, 13, 384)  3456       ['block_7_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (BatchNor  (None, 13, 13, 384)  1536       ['block_7_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (ReLU)  (None, 13, 13, 384)  0           ['block_7_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)       (None, 13, 13, 64)   24576       ['block_7_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchNorma  (None, 13, 13, 64)  256         ['block_7_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_add (Add)              (None, 13, 13, 64)   0           ['block_6_project_BN[0][0]',     \n",
      "                                                                  'block_7_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)        (None, 13, 13, 384)  24576       ['block_7_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNormal  (None, 13, 13, 384)  1536       ['block_8_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)     (None, 13, 13, 384)  0           ['block_8_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_8_depthwise (DepthwiseCo  (None, 13, 13, 384)  3456       ['block_8_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (BatchNor  (None, 13, 13, 384)  1536       ['block_8_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (ReLU)  (None, 13, 13, 384)  0           ['block_8_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)       (None, 13, 13, 64)   24576       ['block_8_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchNorma  (None, 13, 13, 64)  256         ['block_8_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_add (Add)              (None, 13, 13, 64)   0           ['block_7_add[0][0]',            \n",
      "                                                                  'block_8_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)        (None, 13, 13, 384)  24576       ['block_8_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNormal  (None, 13, 13, 384)  1536       ['block_9_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)     (None, 13, 13, 384)  0           ['block_9_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_9_depthwise (DepthwiseCo  (None, 13, 13, 384)  3456       ['block_9_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (BatchNor  (None, 13, 13, 384)  1536       ['block_9_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (ReLU)  (None, 13, 13, 384)  0           ['block_9_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)       (None, 13, 13, 64)   24576       ['block_9_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchNorma  (None, 13, 13, 64)  256         ['block_9_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_add (Add)              (None, 13, 13, 64)   0           ['block_8_add[0][0]',            \n",
      "                                                                  'block_9_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)       (None, 13, 13, 384)  24576       ['block_9_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchNorma  (None, 13, 13, 384)  1536       ['block_10_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU)    (None, 13, 13, 384)  0           ['block_10_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_depthwise (DepthwiseC  (None, 13, 13, 384)  3456       ['block_10_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_10_depthwise_BN (BatchNo  (None, 13, 13, 384)  1536       ['block_10_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_10_depthwise_relu (ReLU)  (None, 13, 13, 384)  0          ['block_10_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)      (None, 13, 13, 96)   36864       ['block_10_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_10_project_BN (BatchNorm  (None, 13, 13, 96)  384         ['block_10_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)       (None, 13, 13, 576)  55296       ['block_10_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchNorma  (None, 13, 13, 576)  2304       ['block_11_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU)    (None, 13, 13, 576)  0           ['block_11_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_11_depthwise (DepthwiseC  (None, 13, 13, 576)  5184       ['block_11_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (BatchNo  (None, 13, 13, 576)  2304       ['block_11_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (ReLU)  (None, 13, 13, 576)  0          ['block_11_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)      (None, 13, 13, 96)   55296       ['block_11_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_11_project_BN (BatchNorm  (None, 13, 13, 96)  384         ['block_11_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_add (Add)             (None, 13, 13, 96)   0           ['block_10_project_BN[0][0]',    \n",
      "                                                                  'block_11_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)       (None, 13, 13, 576)  55296       ['block_11_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchNorma  (None, 13, 13, 576)  2304       ['block_12_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU)    (None, 13, 13, 576)  0           ['block_12_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_12_depthwise (DepthwiseC  (None, 13, 13, 576)  5184       ['block_12_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (BatchNo  (None, 13, 13, 576)  2304       ['block_12_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (ReLU)  (None, 13, 13, 576)  0          ['block_12_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)      (None, 13, 13, 96)   55296       ['block_12_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_12_project_BN (BatchNorm  (None, 13, 13, 96)  384         ['block_12_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_add (Add)             (None, 13, 13, 96)   0           ['block_11_add[0][0]',           \n",
      "                                                                  'block_12_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)       (None, 13, 13, 576)  55296       ['block_12_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchNorma  (None, 13, 13, 576)  2304       ['block_13_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU)    (None, 13, 13, 576)  0           ['block_13_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2D)   (None, 15, 15, 576)  0           ['block_13_expand_relu[0][0]']   \n",
      "                                                                                                  \n",
      " block_13_depthwise (DepthwiseC  (None, 7, 7, 576)   5184        ['block_13_pad[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (BatchNo  (None, 7, 7, 576)   2304        ['block_13_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)   0           ['block_13_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)      (None, 7, 7, 160)    92160       ['block_13_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_13_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_13_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_13_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_14_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_14_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_14_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_14_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_14_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_14_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_14_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_14_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_14_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_14_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_add (Add)             (None, 7, 7, 160)    0           ['block_13_project_BN[0][0]',    \n",
      "                                                                  'block_14_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_14_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_15_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_15_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_15_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_15_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_15_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_15_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_15_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_15_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_15_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_add (Add)             (None, 7, 7, 160)    0           ['block_14_add[0][0]',           \n",
      "                                                                  'block_15_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_15_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_16_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_16_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_16_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_16_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_16_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_16_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)      (None, 7, 7, 320)    307200      ['block_16_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_16_project_BN (BatchNorm  (None, 7, 7, 320)   1280        ['block_16_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)                (None, 7, 7, 1280)   409600      ['block_16_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)  5120        ['Conv_1[0][0]']                 \n",
      "                                                                                                  \n",
      " out_relu (ReLU)                (None, 7, 7, 1280)   0           ['Conv_1_bn[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 62720)        0           ['out_relu[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 62720)       250880      ['flatten_1[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 62720)        0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 100)          6272100     ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 100)         400         ['dense_2[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 100)          0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 50)           5050        ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 50)          200         ['dense_3[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 50)           0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,786,614\n",
      "Trainable params: 6,402,890\n",
      "Non-trainable params: 2,383,724\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Here we can define which layers can be trainable, plus we can define\n",
    "# the output layer from which we can get the features.\n",
    "trainable_layers = [\"\"]\n",
    "output_layer_name = [\"\"]\n",
    "\n",
    "# Load MobileNetV2\n",
    "mobilenetV2 = tf.keras.applications.MobileNetV2(include_top=False, \n",
    "                                                weights=configs['pretrain_weights'], \n",
    "                                                input_shape=input_shape,\n",
    "                                                input_tensor=input0)\n",
    "\n",
    "feature_extractor = tf.keras.models.Model(inputs=input0, \n",
    "                                          outputs=mobilenetV2.output, \n",
    "                                          name=\"mobilenetV2_features\")\n",
    "\n",
    "#set the feture extractor layers as non-trainable\n",
    "for idx,layer in enumerate(feature_extractor.layers):\n",
    "  if layer.name in trainable_layers:\n",
    "    layer.trainable = True\n",
    "  else:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Get the output tensor from a layer of the feature extractor\n",
    "output_extractor = feature_extractor.output\n",
    "#output_extractor = feature_extractor.get_layer(name = output_layer_name).output\n",
    "\n",
    "flatten = Flatten()(output_extractor) # Flatten the output of a Conv layer\n",
    "flatten_norm = BatchNormalization()(flatten) # Apply BatchNormalization()\n",
    "\n",
    "dense2 = Dropout(0.2)(flatten_norm) # Apply Dropout() to the BatchNormalized Flatten layer\n",
    "\n",
    "# Add a Dense layer + Batch Normalization + ReLU\n",
    "dense2 = Dense(100)(dense2)\n",
    "dense2 = BatchNormalization()(dense2)\n",
    "dense2 = Activation(\"relu\")(dense2)\n",
    "\n",
    "# Add a Dense layer + Batch Normalization + SoftMax\n",
    "dense3 = Dense(num_classes)(dense2)\n",
    "dense3 = BatchNormalization()(dense3)\n",
    "dense3 = Activation(\"softmax\")(dense3)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=input0, outputs=dense3, name=\"MobileNetV2\")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "configs['model_name'] = model.name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobileNetV3Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we can define which layers can be trainable, plus we can define\n",
    "# the output layer from which we can get the features.\n",
    "trainable_layers = [\"\"]\n",
    "output_layer_name = [\"\"]\n",
    "\n",
    "# Load MobileNetV3Small\n",
    "mobileNetV3Small = tf.keras.applications.MobileNetV3Small(include_top=False, \n",
    "                                                          weights=configs['pretrain_weights'], \n",
    "                                                          input_shape=input_shape,\n",
    "                                                          input_tensor=input0)\n",
    "\n",
    "feature_extractor = tf.keras.models.Model(inputs=input0, \n",
    "                                          outputs=mobileNetV3Small.output, \n",
    "                                          name=\"MobileNetV3Small_features\")\n",
    "\n",
    "#set the feture extractor layers as non-trainable\n",
    "for idx,layer in enumerate(feature_extractor.layers):\n",
    "  if layer.name in trainable_layers:\n",
    "    layer.trainable = True\n",
    "  else:\n",
    "    layer.trainable = False\n",
    "\n",
    "# get the output tensor from a layer of the feature extractor\n",
    "output_extractor = feature_extractor.output\n",
    "#output_extractor = feature_extractor.get_layer(name = output_layer_name).output\n",
    "\n",
    "# flat the output of a Conv layer\n",
    "flatten = Flatten()(output_extractor) \n",
    "flatten_norm = BatchNormalization()(flatten)\n",
    "\n",
    "dense2 = Dropout(0.2)(flatten_norm)\n",
    "\n",
    "# add a Dense layer\n",
    "dense2 = Dense(100)(dense2)\n",
    "dense2 = BatchNormalization()(dense2)\n",
    "dense2 = Activation(\"relu\")(dense2)\n",
    "\n",
    "# add the final output layer\n",
    "dense3 = Dense(num_classes)(dense2)\n",
    "dense3 = BatchNormalization()(dense3)\n",
    "dense3 = Activation(\"softmax\")(dense3)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=input0, outputs=dense3, name=\"MobileNetV3Small\")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "configs['model_name'] = model.name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xception\n",
    "XCeption needs the Nesterov optimizer, as per its paper.<br><br> - optimizer = optimizers.SGD(learning_rate=config['init_learning_rate'], nesterov=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83683744/83683744 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Here we can define which layers can be trainable, plus we can define\n",
    "# the output layer from which we can get the features.\n",
    "trainable_layers = [\"\"]\n",
    "output_layer_name = [\"\"]\n",
    "    \n",
    "# Load Xception model\n",
    "xceptionModel = tf.keras.applications.xception.Xception(include_top=False, \n",
    "                                                            classes=num_classes, \n",
    "                                                            weights=configs['pretrain_weights'],\n",
    "                                                            input_shape=input_shape, \n",
    "                                                            input_tensor=input0)\n",
    "\n",
    "feature_extractor = tf.keras.models.Model(inputs=input0, outputs=xceptionModel.output, name=\"Xception_features\")\n",
    "feature_extractor.trainable=True\n",
    "\n",
    "# get the output tensor from a layer of the feature extractor\n",
    "#output_extractor = feature_extractor.get_layer(name = output_layer_name).output\n",
    "output_extractor = feature_extractor.output\n",
    "\n",
    "# flat the output of a Conv layer\n",
    "flatten = Flatten()(output_extractor)\n",
    "flatten_norm = BatchNormalization()(flatten)\n",
    "\n",
    "# add a Dense layer\n",
    "dense2 = Dense(100)(flatten_norm)\n",
    "dense2 = Activation(\"relu\")(dense2)\n",
    "\n",
    "# add the final output layer\n",
    "dense3 = Dense(num_classes)(dense2)\n",
    "dense3 = Activation(\"softmax\")(dense3)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=input0, outputs=dense3, name=\"Xception\")\n",
    "\n",
    "model.summary()\n",
    "configs['model_name'] = model.name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16_features\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 200, 200, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 200, 200, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 200, 200, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 100, 100, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 100, 100, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 100, 100, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 50, 50, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 50, 50, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 50, 50, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 50, 50, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 50, 50, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 25, 25, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 25, 25, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 25, 25, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 25, 25, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 25, 25, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 12, 12, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"VGG16Edited\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 200, 200, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 200, 200, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 200, 200, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 100, 100, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 100, 100, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 100, 100, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 50, 50, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 50, 50, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 50, 50, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 50, 50, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 50, 50, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 25, 25, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 25, 25, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 25, 25, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 25, 25, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 25, 25, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 12, 12, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 18432)             0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 18432)            73728     \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 18432)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               1843300   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " tf.nn.relu_1 (TFOpLambda)   (None, 100)               0         \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 50)               200       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 50)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,947,062\n",
      "Trainable params: 4,245,322\n",
      "Non-trainable params: 17,701,740\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Here we can define which layers can be trainable, plus we can define\n",
    "# the output layer from which we can get the features.\n",
    "trainable_layers = [\"block5_conv3\"]\n",
    "output_layer_name = [\"block5_pool\"]\n",
    "\n",
    "# Load VGG19 model\n",
    "VGG19Model = tf.keras.applications.vgg19.VGG19(include_top=False, \n",
    "                                                weights=configs['pretrain_weights'],\n",
    "                                                input_shape=input_shape,\n",
    "                                                input_tensor=input0)\n",
    "\n",
    "feature_extractor = tf.keras.models.Model(inputs=input0, \n",
    "                                          outputs=VGG19Model.output, \n",
    "                                          name=\"VGG19_features\")\n",
    "\n",
    "# set the feture extractor layers as non-trainable\n",
    "for idx,layer in enumerate(feature_extractor.layers):\n",
    "  if layer.name in trainable_layers:\n",
    "    layer.trainable = True\n",
    "  else:\n",
    "    layer.trainable = False\n",
    "\n",
    "# get the output tensor from a layer of the feature extractor\n",
    "output_extractor = feature_extractor.get_layer(name = output_layer_name).output\n",
    "\n",
    "output_extractor = MaxPooling2D(pool_size=(4,4))(output_extractor)\n",
    "\n",
    "# flat the output of a Conv layer\n",
    "flatten = Flatten()(output_extractor) \n",
    "flatten_norm = BatchNormalization()(flatten)\n",
    "\n",
    "dense2 = Dropout(0.2)(flatten_norm)\n",
    "\n",
    "# add a Dense layer\n",
    "dense2 = Dense(100)(dense2)\n",
    "dense2 = BatchNormalization()(dense2)\n",
    "dense2 = tf.keras.activations.relu(dense2)\n",
    "dense2 = Activation(\"relu\")(dense2)\n",
    "\n",
    "# add the final output layer\n",
    "dense3 = Dense(num_classes)(dense2)\n",
    "dense3 = BatchNormalization()(dense3)\n",
    "dense3 = Activation(\"softmax\")(dense3)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=input0, outputs=dense3, name=\"VGG19\")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "configs['model_name'] = model.name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16\n",
    "Best model in this notebook:\n",
    "- Acc  = 0.9135\n",
    "- Loss = 0.2939"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VGG16Edited\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 200, 200, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 200, 200, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 200, 200, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 100, 100, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 100, 100, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 100, 100, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 50, 50, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 50, 50, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 50, 50, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 50, 50, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 25, 25, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 25, 25, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 25, 25, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 25, 25, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 12, 12, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " average_pooling2d_2 (Averag  (None, 1, 1, 512)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               51300     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 50)               200       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 50)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,773,686\n",
      "Trainable params: 2,417,482\n",
      "Non-trainable params: 12,356,204\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Here we can define which layers can be trainable, plus we can define\n",
    "# the output layer from which we can get the features.\n",
    "trainable_layers = [\"block5_conv3\"]\n",
    "output_layer_name = \"block5_pool\"\n",
    "\n",
    "# Load VGG16 model\n",
    "VGG16Model = tf.keras.applications.vgg16.VGG16(include_top=False,\n",
    "                                                weights=configs['pretrain_weights'], \n",
    "                                                input_shape=input_shape,\n",
    "                                                input_tensor=input0)\n",
    "\n",
    "feature_extractor = tf.keras.models.Model(inputs=input0, \n",
    "                                          outputs=VGG16Model.output, \n",
    "                                          name=\"VGG16_Features\")\n",
    "\n",
    "# Set the feature extractor layers as non-trainable\n",
    "for idx, layer in enumerate(feature_extractor.layers):\n",
    "  if layer.name in trainable_layers:\n",
    "    layer.trainable = True\n",
    "  else:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Get the output tensor from a layer of the feature extractor\n",
    "output_extractor = feature_extractor.get_layer(name = output_layer_name).output\n",
    "\n",
    "output_extractor = AveragePooling2D(pool_size=(4,4))(output_extractor)\n",
    "\n",
    "# flat the output of a Conv layer\n",
    "flatten = Flatten()(output_extractor) \n",
    "flatten_norm = BatchNormalization()(flatten)\n",
    "\n",
    "dense2 = Dropout(0.2)(flatten_norm)\n",
    "\n",
    "# add a Dense layer\n",
    "dense2 = Dense(100)(dense2)\n",
    "dense2 = BatchNormalization()(dense2)\n",
    "dense2 = Activation(\"relu\")(dense2)\n",
    "\n",
    "# add the final output layer\n",
    "dense3 = Dense(num_classes)(dense2)\n",
    "dense3 = BatchNormalization()(dense3)\n",
    "dense3 = Activation(\"softmax\")(dense3)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=input0, outputs=dense3, name=\"VGG16\")\n",
    "\n",
    "# build the transfer model\n",
    "model.summary()\n",
    "\n",
    "configs['model_name'] = model.name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet152\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 200, 200, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 206, 206, 3)  0           ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 100, 100, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 100, 100, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 100, 100, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 102, 102, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 50, 50, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 50, 50, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 50, 50, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 50, 50, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 50, 50, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 50, 50, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 50, 50, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 50, 50, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 50, 50, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 50, 50, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 50, 50, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 50, 50, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 50, 50, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 50, 50, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 50, 50, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 50, 50, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 50, 50, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 50, 50, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 50, 50, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 50, 50, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 50, 50, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 50, 50, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 50, 50, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 50, 50, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 50, 50, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 50, 50, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 50, 50, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 50, 50, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 50, 50, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 50, 50, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 50, 50, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 50, 50, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 50, 50, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 25, 25, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 25, 25, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 25, 25, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 25, 25, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 25, 25, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 25, 25, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 25, 25, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 25, 25, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 25, 25, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 25, 25, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 25, 25, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 25, 25, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 25, 25, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 25, 25, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 25, 25, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 25, 25, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 25, 25, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 25, 25, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 25, 25, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 25, 25, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 25, 25, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 25, 25, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 25, 25, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 25, 25, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 25, 25, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 25, 25, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 25, 25, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 25, 25, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 25, 25, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 25, 25, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 25, 25, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 25, 25, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 25, 25, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 25, 25, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 25, 25, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 25, 25, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 25, 25, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 25, 25, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 25, 25, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 25, 25, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 25, 25, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 25, 25, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block5_1_conv (Conv2D)   (None, 25, 25, 128)  65664       ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block5_1_bn (BatchNormal  (None, 25, 25, 128)  512        ['conv3_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block5_1_relu (Activatio  (None, 25, 25, 128)  0          ['conv3_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block5_2_conv (Conv2D)   (None, 25, 25, 128)  147584      ['conv3_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block5_2_bn (BatchNormal  (None, 25, 25, 128)  512        ['conv3_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block5_2_relu (Activatio  (None, 25, 25, 128)  0          ['conv3_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block5_3_conv (Conv2D)   (None, 25, 25, 512)  66048       ['conv3_block5_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block5_3_bn (BatchNormal  (None, 25, 25, 512)  2048       ['conv3_block5_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block5_add (Add)         (None, 25, 25, 512)  0           ['conv3_block4_out[0][0]',       \n",
      "                                                                  'conv3_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block5_out (Activation)  (None, 25, 25, 512)  0           ['conv3_block5_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block6_1_conv (Conv2D)   (None, 25, 25, 128)  65664       ['conv3_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block6_1_bn (BatchNormal  (None, 25, 25, 128)  512        ['conv3_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block6_1_relu (Activatio  (None, 25, 25, 128)  0          ['conv3_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block6_2_conv (Conv2D)   (None, 25, 25, 128)  147584      ['conv3_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block6_2_bn (BatchNormal  (None, 25, 25, 128)  512        ['conv3_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block6_2_relu (Activatio  (None, 25, 25, 128)  0          ['conv3_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block6_3_conv (Conv2D)   (None, 25, 25, 512)  66048       ['conv3_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block6_3_bn (BatchNormal  (None, 25, 25, 512)  2048       ['conv3_block6_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block6_add (Add)         (None, 25, 25, 512)  0           ['conv3_block5_out[0][0]',       \n",
      "                                                                  'conv3_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block6_out (Activation)  (None, 25, 25, 512)  0           ['conv3_block6_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block7_1_conv (Conv2D)   (None, 25, 25, 128)  65664       ['conv3_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block7_1_bn (BatchNormal  (None, 25, 25, 128)  512        ['conv3_block7_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block7_1_relu (Activatio  (None, 25, 25, 128)  0          ['conv3_block7_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block7_2_conv (Conv2D)   (None, 25, 25, 128)  147584      ['conv3_block7_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block7_2_bn (BatchNormal  (None, 25, 25, 128)  512        ['conv3_block7_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block7_2_relu (Activatio  (None, 25, 25, 128)  0          ['conv3_block7_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block7_3_conv (Conv2D)   (None, 25, 25, 512)  66048       ['conv3_block7_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block7_3_bn (BatchNormal  (None, 25, 25, 512)  2048       ['conv3_block7_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block7_add (Add)         (None, 25, 25, 512)  0           ['conv3_block6_out[0][0]',       \n",
      "                                                                  'conv3_block7_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block7_out (Activation)  (None, 25, 25, 512)  0           ['conv3_block7_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block8_1_conv (Conv2D)   (None, 25, 25, 128)  65664       ['conv3_block7_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block8_1_bn (BatchNormal  (None, 25, 25, 128)  512        ['conv3_block8_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block8_1_relu (Activatio  (None, 25, 25, 128)  0          ['conv3_block8_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block8_2_conv (Conv2D)   (None, 25, 25, 128)  147584      ['conv3_block8_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block8_2_bn (BatchNormal  (None, 25, 25, 128)  512        ['conv3_block8_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block8_2_relu (Activatio  (None, 25, 25, 128)  0          ['conv3_block8_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block8_3_conv (Conv2D)   (None, 25, 25, 512)  66048       ['conv3_block8_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block8_3_bn (BatchNormal  (None, 25, 25, 512)  2048       ['conv3_block8_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block8_add (Add)         (None, 25, 25, 512)  0           ['conv3_block7_out[0][0]',       \n",
      "                                                                  'conv3_block8_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block8_out (Activation)  (None, 25, 25, 512)  0           ['conv3_block8_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 13, 13, 256)  131328      ['conv3_block8_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 13, 13, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 13, 13, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 13, 13, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 13, 13, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 13, 13, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 13, 13, 1024  525312      ['conv3_block8_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 13, 13, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 13, 13, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 13, 13, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 13, 13, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 13, 13, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 13, 13, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 13, 13, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 13, 13, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 13, 13, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 13, 13, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 13, 13, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 13, 13, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 13, 13, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 13, 13, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 13, 13, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 13, 13, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 13, 13, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 13, 13, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 13, 13, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 13, 13, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 13, 13, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 13, 13, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 13, 13, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 13, 13, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 13, 13, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 13, 13, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 13, 13, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 13, 13, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 13, 13, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 13, 13, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 13, 13, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 13, 13, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 13, 13, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 13, 13, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 13, 13, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 13, 13, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 13, 13, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 13, 13, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 13, 13, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 13, 13, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 13, 13, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 13, 13, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 13, 13, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 13, 13, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 13, 13, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 13, 13, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 13, 13, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 13, 13, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 13, 13, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 13, 13, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 13, 13, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 13, 13, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 13, 13, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 13, 13, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 13, 13, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block7_1_conv (Conv2D)   (None, 13, 13, 256)  262400      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block7_1_bn (BatchNormal  (None, 13, 13, 256)  1024       ['conv4_block7_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block7_1_relu (Activatio  (None, 13, 13, 256)  0          ['conv4_block7_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block7_2_conv (Conv2D)   (None, 13, 13, 256)  590080      ['conv4_block7_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block7_2_bn (BatchNormal  (None, 13, 13, 256)  1024       ['conv4_block7_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block7_2_relu (Activatio  (None, 13, 13, 256)  0          ['conv4_block7_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block7_3_conv (Conv2D)   (None, 13, 13, 1024  263168      ['conv4_block7_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block7_3_bn (BatchNormal  (None, 13, 13, 1024  4096       ['conv4_block7_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block7_add (Add)         (None, 13, 13, 1024  0           ['conv4_block6_out[0][0]',       \n",
      "                                )                                 'conv4_block7_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block7_out (Activation)  (None, 13, 13, 1024  0           ['conv4_block7_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block8_1_conv (Conv2D)   (None, 13, 13, 256)  262400      ['conv4_block7_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block8_1_bn (BatchNormal  (None, 13, 13, 256)  1024       ['conv4_block8_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block8_1_relu (Activatio  (None, 13, 13, 256)  0          ['conv4_block8_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block8_2_conv (Conv2D)   (None, 13, 13, 256)  590080      ['conv4_block8_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block8_2_bn (BatchNormal  (None, 13, 13, 256)  1024       ['conv4_block8_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block8_2_relu (Activatio  (None, 13, 13, 256)  0          ['conv4_block8_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block8_3_conv (Conv2D)   (None, 13, 13, 1024  263168      ['conv4_block8_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block8_3_bn (BatchNormal  (None, 13, 13, 1024  4096       ['conv4_block8_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block8_add (Add)         (None, 13, 13, 1024  0           ['conv4_block7_out[0][0]',       \n",
      "                                )                                 'conv4_block8_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block8_out (Activation)  (None, 13, 13, 1024  0           ['conv4_block8_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block9_1_conv (Conv2D)   (None, 13, 13, 256)  262400      ['conv4_block8_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block9_1_bn (BatchNormal  (None, 13, 13, 256)  1024       ['conv4_block9_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block9_1_relu (Activatio  (None, 13, 13, 256)  0          ['conv4_block9_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block9_2_conv (Conv2D)   (None, 13, 13, 256)  590080      ['conv4_block9_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block9_2_bn (BatchNormal  (None, 13, 13, 256)  1024       ['conv4_block9_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block9_2_relu (Activatio  (None, 13, 13, 256)  0          ['conv4_block9_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block9_3_conv (Conv2D)   (None, 13, 13, 1024  263168      ['conv4_block9_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block9_3_bn (BatchNormal  (None, 13, 13, 1024  4096       ['conv4_block9_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block9_add (Add)         (None, 13, 13, 1024  0           ['conv4_block8_out[0][0]',       \n",
      "                                )                                 'conv4_block9_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block9_out (Activation)  (None, 13, 13, 1024  0           ['conv4_block9_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block10_1_conv (Conv2D)  (None, 13, 13, 256)  262400      ['conv4_block9_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block10_1_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block10_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block10_1_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block10_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block10_2_conv (Conv2D)  (None, 13, 13, 256)  590080      ['conv4_block10_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block10_2_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block10_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block10_2_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block10_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block10_3_conv (Conv2D)  (None, 13, 13, 1024  263168      ['conv4_block10_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block10_3_bn (BatchNorma  (None, 13, 13, 1024  4096       ['conv4_block10_3_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block10_add (Add)        (None, 13, 13, 1024  0           ['conv4_block9_out[0][0]',       \n",
      "                                )                                 'conv4_block10_3_bn[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block10_out (Activation)  (None, 13, 13, 1024  0          ['conv4_block10_add[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block11_1_conv (Conv2D)  (None, 13, 13, 256)  262400      ['conv4_block10_out[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block11_1_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block11_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block11_1_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block11_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block11_2_conv (Conv2D)  (None, 13, 13, 256)  590080      ['conv4_block11_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block11_2_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block11_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block11_2_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block11_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block11_3_conv (Conv2D)  (None, 13, 13, 1024  263168      ['conv4_block11_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block11_3_bn (BatchNorma  (None, 13, 13, 1024  4096       ['conv4_block11_3_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block11_add (Add)        (None, 13, 13, 1024  0           ['conv4_block10_out[0][0]',      \n",
      "                                )                                 'conv4_block11_3_bn[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block11_out (Activation)  (None, 13, 13, 1024  0          ['conv4_block11_add[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block12_1_conv (Conv2D)  (None, 13, 13, 256)  262400      ['conv4_block11_out[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block12_1_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block12_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block12_1_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block12_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block12_2_conv (Conv2D)  (None, 13, 13, 256)  590080      ['conv4_block12_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block12_2_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block12_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block12_2_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block12_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block12_3_conv (Conv2D)  (None, 13, 13, 1024  263168      ['conv4_block12_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block12_3_bn (BatchNorma  (None, 13, 13, 1024  4096       ['conv4_block12_3_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block12_add (Add)        (None, 13, 13, 1024  0           ['conv4_block11_out[0][0]',      \n",
      "                                )                                 'conv4_block12_3_bn[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block12_out (Activation)  (None, 13, 13, 1024  0          ['conv4_block12_add[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block13_1_conv (Conv2D)  (None, 13, 13, 256)  262400      ['conv4_block12_out[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block13_1_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block13_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block13_1_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block13_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block13_2_conv (Conv2D)  (None, 13, 13, 256)  590080      ['conv4_block13_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block13_2_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block13_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block13_2_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block13_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block13_3_conv (Conv2D)  (None, 13, 13, 1024  263168      ['conv4_block13_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block13_3_bn (BatchNorma  (None, 13, 13, 1024  4096       ['conv4_block13_3_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block13_add (Add)        (None, 13, 13, 1024  0           ['conv4_block12_out[0][0]',      \n",
      "                                )                                 'conv4_block13_3_bn[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block13_out (Activation)  (None, 13, 13, 1024  0          ['conv4_block13_add[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block14_1_conv (Conv2D)  (None, 13, 13, 256)  262400      ['conv4_block13_out[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block14_1_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block14_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block14_1_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block14_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block14_2_conv (Conv2D)  (None, 13, 13, 256)  590080      ['conv4_block14_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block14_2_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block14_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block14_2_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block14_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block14_3_conv (Conv2D)  (None, 13, 13, 1024  263168      ['conv4_block14_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block14_3_bn (BatchNorma  (None, 13, 13, 1024  4096       ['conv4_block14_3_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block14_add (Add)        (None, 13, 13, 1024  0           ['conv4_block13_out[0][0]',      \n",
      "                                )                                 'conv4_block14_3_bn[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block14_out (Activation)  (None, 13, 13, 1024  0          ['conv4_block14_add[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block15_1_conv (Conv2D)  (None, 13, 13, 256)  262400      ['conv4_block14_out[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block15_1_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block15_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block15_1_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block15_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block15_2_conv (Conv2D)  (None, 13, 13, 256)  590080      ['conv4_block15_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block15_2_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block15_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block15_2_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block15_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block15_3_conv (Conv2D)  (None, 13, 13, 1024  263168      ['conv4_block15_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block15_3_bn (BatchNorma  (None, 13, 13, 1024  4096       ['conv4_block15_3_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block15_add (Add)        (None, 13, 13, 1024  0           ['conv4_block14_out[0][0]',      \n",
      "                                )                                 'conv4_block15_3_bn[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block15_out (Activation)  (None, 13, 13, 1024  0          ['conv4_block15_add[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block16_1_conv (Conv2D)  (None, 13, 13, 256)  262400      ['conv4_block15_out[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block16_1_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block16_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block16_1_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block16_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block16_2_conv (Conv2D)  (None, 13, 13, 256)  590080      ['conv4_block16_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block16_2_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block16_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block16_2_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block16_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block16_3_conv (Conv2D)  (None, 13, 13, 1024  263168      ['conv4_block16_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block16_3_bn (BatchNorma  (None, 13, 13, 1024  4096       ['conv4_block16_3_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block16_add (Add)        (None, 13, 13, 1024  0           ['conv4_block15_out[0][0]',      \n",
      "                                )                                 'conv4_block16_3_bn[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block16_out (Activation)  (None, 13, 13, 1024  0          ['conv4_block16_add[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block17_1_conv (Conv2D)  (None, 13, 13, 256)  262400      ['conv4_block16_out[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block17_1_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block17_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block17_1_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block17_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block17_2_conv (Conv2D)  (None, 13, 13, 256)  590080      ['conv4_block17_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block17_2_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block17_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block17_2_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block17_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block17_3_conv (Conv2D)  (None, 13, 13, 1024  263168      ['conv4_block17_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block17_3_bn (BatchNorma  (None, 13, 13, 1024  4096       ['conv4_block17_3_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block17_add (Add)        (None, 13, 13, 1024  0           ['conv4_block16_out[0][0]',      \n",
      "                                )                                 'conv4_block17_3_bn[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block17_out (Activation)  (None, 13, 13, 1024  0          ['conv4_block17_add[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block18_1_conv (Conv2D)  (None, 13, 13, 256)  262400      ['conv4_block17_out[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block18_1_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block18_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block18_1_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block18_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block18_2_conv (Conv2D)  (None, 13, 13, 256)  590080      ['conv4_block18_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block18_2_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block18_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block18_2_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block18_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block18_3_conv (Conv2D)  (None, 13, 13, 1024  263168      ['conv4_block18_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block18_3_bn (BatchNorma  (None, 13, 13, 1024  4096       ['conv4_block18_3_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block18_add (Add)        (None, 13, 13, 1024  0           ['conv4_block17_out[0][0]',      \n",
      "                                )                                 'conv4_block18_3_bn[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block18_out (Activation)  (None, 13, 13, 1024  0          ['conv4_block18_add[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block19_1_conv (Conv2D)  (None, 13, 13, 256)  262400      ['conv4_block18_out[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block19_1_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block19_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block19_1_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block19_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block19_2_conv (Conv2D)  (None, 13, 13, 256)  590080      ['conv4_block19_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block19_2_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block19_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block19_2_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block19_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block19_3_conv (Conv2D)  (None, 13, 13, 1024  263168      ['conv4_block19_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block19_3_bn (BatchNorma  (None, 13, 13, 1024  4096       ['conv4_block19_3_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block19_add (Add)        (None, 13, 13, 1024  0           ['conv4_block18_out[0][0]',      \n",
      "                                )                                 'conv4_block19_3_bn[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block19_out (Activation)  (None, 13, 13, 1024  0          ['conv4_block19_add[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block20_1_conv (Conv2D)  (None, 13, 13, 256)  262400      ['conv4_block19_out[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block20_1_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block20_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block20_1_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block20_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block20_2_conv (Conv2D)  (None, 13, 13, 256)  590080      ['conv4_block20_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block20_2_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block20_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block20_2_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block20_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block20_3_conv (Conv2D)  (None, 13, 13, 1024  263168      ['conv4_block20_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block20_3_bn (BatchNorma  (None, 13, 13, 1024  4096       ['conv4_block20_3_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block20_add (Add)        (None, 13, 13, 1024  0           ['conv4_block19_out[0][0]',      \n",
      "                                )                                 'conv4_block20_3_bn[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block20_out (Activation)  (None, 13, 13, 1024  0          ['conv4_block20_add[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block21_1_conv (Conv2D)  (None, 13, 13, 256)  262400      ['conv4_block20_out[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block21_1_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block21_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block21_1_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block21_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block21_2_conv (Conv2D)  (None, 13, 13, 256)  590080      ['conv4_block21_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block21_2_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block21_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block21_2_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block21_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block21_3_conv (Conv2D)  (None, 13, 13, 1024  263168      ['conv4_block21_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block21_3_bn (BatchNorma  (None, 13, 13, 1024  4096       ['conv4_block21_3_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block21_add (Add)        (None, 13, 13, 1024  0           ['conv4_block20_out[0][0]',      \n",
      "                                )                                 'conv4_block21_3_bn[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block21_out (Activation)  (None, 13, 13, 1024  0          ['conv4_block21_add[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block22_1_conv (Conv2D)  (None, 13, 13, 256)  262400      ['conv4_block21_out[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block22_1_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block22_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block22_1_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block22_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block22_2_conv (Conv2D)  (None, 13, 13, 256)  590080      ['conv4_block22_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block22_2_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block22_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block22_2_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block22_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block22_3_conv (Conv2D)  (None, 13, 13, 1024  263168      ['conv4_block22_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block22_3_bn (BatchNorma  (None, 13, 13, 1024  4096       ['conv4_block22_3_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block22_add (Add)        (None, 13, 13, 1024  0           ['conv4_block21_out[0][0]',      \n",
      "                                )                                 'conv4_block22_3_bn[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block22_out (Activation)  (None, 13, 13, 1024  0          ['conv4_block22_add[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block23_1_conv (Conv2D)  (None, 13, 13, 256)  262400      ['conv4_block22_out[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block23_1_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block23_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block23_1_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block23_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block23_2_conv (Conv2D)  (None, 13, 13, 256)  590080      ['conv4_block23_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block23_2_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block23_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block23_2_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block23_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block23_3_conv (Conv2D)  (None, 13, 13, 1024  263168      ['conv4_block23_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block23_3_bn (BatchNorma  (None, 13, 13, 1024  4096       ['conv4_block23_3_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block23_add (Add)        (None, 13, 13, 1024  0           ['conv4_block22_out[0][0]',      \n",
      "                                )                                 'conv4_block23_3_bn[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block23_out (Activation)  (None, 13, 13, 1024  0          ['conv4_block23_add[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block24_1_conv (Conv2D)  (None, 13, 13, 256)  262400      ['conv4_block23_out[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block24_1_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block24_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block24_1_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block24_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block24_2_conv (Conv2D)  (None, 13, 13, 256)  590080      ['conv4_block24_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block24_2_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block24_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block24_2_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block24_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block24_3_conv (Conv2D)  (None, 13, 13, 1024  263168      ['conv4_block24_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block24_3_bn (BatchNorma  (None, 13, 13, 1024  4096       ['conv4_block24_3_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block24_add (Add)        (None, 13, 13, 1024  0           ['conv4_block23_out[0][0]',      \n",
      "                                )                                 'conv4_block24_3_bn[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block24_out (Activation)  (None, 13, 13, 1024  0          ['conv4_block24_add[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block25_1_conv (Conv2D)  (None, 13, 13, 256)  262400      ['conv4_block24_out[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block25_1_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block25_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block25_1_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block25_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block25_2_conv (Conv2D)  (None, 13, 13, 256)  590080      ['conv4_block25_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block25_2_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block25_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block25_2_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block25_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block25_3_conv (Conv2D)  (None, 13, 13, 1024  263168      ['conv4_block25_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block25_3_bn (BatchNorma  (None, 13, 13, 1024  4096       ['conv4_block25_3_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block25_add (Add)        (None, 13, 13, 1024  0           ['conv4_block24_out[0][0]',      \n",
      "                                )                                 'conv4_block25_3_bn[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block25_out (Activation)  (None, 13, 13, 1024  0          ['conv4_block25_add[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block26_1_conv (Conv2D)  (None, 13, 13, 256)  262400      ['conv4_block25_out[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block26_1_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block26_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block26_1_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block26_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block26_2_conv (Conv2D)  (None, 13, 13, 256)  590080      ['conv4_block26_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block26_2_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block26_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block26_2_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block26_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block26_3_conv (Conv2D)  (None, 13, 13, 1024  263168      ['conv4_block26_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block26_3_bn (BatchNorma  (None, 13, 13, 1024  4096       ['conv4_block26_3_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block26_add (Add)        (None, 13, 13, 1024  0           ['conv4_block25_out[0][0]',      \n",
      "                                )                                 'conv4_block26_3_bn[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block26_out (Activation)  (None, 13, 13, 1024  0          ['conv4_block26_add[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block27_1_conv (Conv2D)  (None, 13, 13, 256)  262400      ['conv4_block26_out[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block27_1_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block27_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block27_1_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block27_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block27_2_conv (Conv2D)  (None, 13, 13, 256)  590080      ['conv4_block27_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block27_2_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block27_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block27_2_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block27_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block27_3_conv (Conv2D)  (None, 13, 13, 1024  263168      ['conv4_block27_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block27_3_bn (BatchNorma  (None, 13, 13, 1024  4096       ['conv4_block27_3_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block27_add (Add)        (None, 13, 13, 1024  0           ['conv4_block26_out[0][0]',      \n",
      "                                )                                 'conv4_block27_3_bn[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block27_out (Activation)  (None, 13, 13, 1024  0          ['conv4_block27_add[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block28_1_conv (Conv2D)  (None, 13, 13, 256)  262400      ['conv4_block27_out[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block28_1_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block28_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block28_1_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block28_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block28_2_conv (Conv2D)  (None, 13, 13, 256)  590080      ['conv4_block28_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block28_2_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block28_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block28_2_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block28_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block28_3_conv (Conv2D)  (None, 13, 13, 1024  263168      ['conv4_block28_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block28_3_bn (BatchNorma  (None, 13, 13, 1024  4096       ['conv4_block28_3_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block28_add (Add)        (None, 13, 13, 1024  0           ['conv4_block27_out[0][0]',      \n",
      "                                )                                 'conv4_block28_3_bn[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block28_out (Activation)  (None, 13, 13, 1024  0          ['conv4_block28_add[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block29_1_conv (Conv2D)  (None, 13, 13, 256)  262400      ['conv4_block28_out[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block29_1_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block29_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block29_1_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block29_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block29_2_conv (Conv2D)  (None, 13, 13, 256)  590080      ['conv4_block29_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block29_2_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block29_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block29_2_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block29_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block29_3_conv (Conv2D)  (None, 13, 13, 1024  263168      ['conv4_block29_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block29_3_bn (BatchNorma  (None, 13, 13, 1024  4096       ['conv4_block29_3_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block29_add (Add)        (None, 13, 13, 1024  0           ['conv4_block28_out[0][0]',      \n",
      "                                )                                 'conv4_block29_3_bn[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block29_out (Activation)  (None, 13, 13, 1024  0          ['conv4_block29_add[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block30_1_conv (Conv2D)  (None, 13, 13, 256)  262400      ['conv4_block29_out[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block30_1_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block30_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block30_1_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block30_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block30_2_conv (Conv2D)  (None, 13, 13, 256)  590080      ['conv4_block30_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block30_2_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block30_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block30_2_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block30_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block30_3_conv (Conv2D)  (None, 13, 13, 1024  263168      ['conv4_block30_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block30_3_bn (BatchNorma  (None, 13, 13, 1024  4096       ['conv4_block30_3_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block30_add (Add)        (None, 13, 13, 1024  0           ['conv4_block29_out[0][0]',      \n",
      "                                )                                 'conv4_block30_3_bn[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block30_out (Activation)  (None, 13, 13, 1024  0          ['conv4_block30_add[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block31_1_conv (Conv2D)  (None, 13, 13, 256)  262400      ['conv4_block30_out[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block31_1_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block31_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block31_1_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block31_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block31_2_conv (Conv2D)  (None, 13, 13, 256)  590080      ['conv4_block31_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block31_2_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block31_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block31_2_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block31_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block31_3_conv (Conv2D)  (None, 13, 13, 1024  263168      ['conv4_block31_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block31_3_bn (BatchNorma  (None, 13, 13, 1024  4096       ['conv4_block31_3_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block31_add (Add)        (None, 13, 13, 1024  0           ['conv4_block30_out[0][0]',      \n",
      "                                )                                 'conv4_block31_3_bn[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block31_out (Activation)  (None, 13, 13, 1024  0          ['conv4_block31_add[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block32_1_conv (Conv2D)  (None, 13, 13, 256)  262400      ['conv4_block31_out[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block32_1_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block32_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block32_1_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block32_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block32_2_conv (Conv2D)  (None, 13, 13, 256)  590080      ['conv4_block32_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block32_2_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block32_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block32_2_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block32_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block32_3_conv (Conv2D)  (None, 13, 13, 1024  263168      ['conv4_block32_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block32_3_bn (BatchNorma  (None, 13, 13, 1024  4096       ['conv4_block32_3_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block32_add (Add)        (None, 13, 13, 1024  0           ['conv4_block31_out[0][0]',      \n",
      "                                )                                 'conv4_block32_3_bn[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block32_out (Activation)  (None, 13, 13, 1024  0          ['conv4_block32_add[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block33_1_conv (Conv2D)  (None, 13, 13, 256)  262400      ['conv4_block32_out[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block33_1_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block33_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block33_1_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block33_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block33_2_conv (Conv2D)  (None, 13, 13, 256)  590080      ['conv4_block33_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block33_2_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block33_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block33_2_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block33_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block33_3_conv (Conv2D)  (None, 13, 13, 1024  263168      ['conv4_block33_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block33_3_bn (BatchNorma  (None, 13, 13, 1024  4096       ['conv4_block33_3_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block33_add (Add)        (None, 13, 13, 1024  0           ['conv4_block32_out[0][0]',      \n",
      "                                )                                 'conv4_block33_3_bn[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block33_out (Activation)  (None, 13, 13, 1024  0          ['conv4_block33_add[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block34_1_conv (Conv2D)  (None, 13, 13, 256)  262400      ['conv4_block33_out[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block34_1_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block34_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block34_1_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block34_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block34_2_conv (Conv2D)  (None, 13, 13, 256)  590080      ['conv4_block34_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block34_2_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block34_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block34_2_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block34_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block34_3_conv (Conv2D)  (None, 13, 13, 1024  263168      ['conv4_block34_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block34_3_bn (BatchNorma  (None, 13, 13, 1024  4096       ['conv4_block34_3_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block34_add (Add)        (None, 13, 13, 1024  0           ['conv4_block33_out[0][0]',      \n",
      "                                )                                 'conv4_block34_3_bn[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block34_out (Activation)  (None, 13, 13, 1024  0          ['conv4_block34_add[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block35_1_conv (Conv2D)  (None, 13, 13, 256)  262400      ['conv4_block34_out[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block35_1_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block35_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block35_1_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block35_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block35_2_conv (Conv2D)  (None, 13, 13, 256)  590080      ['conv4_block35_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block35_2_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block35_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block35_2_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block35_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block35_3_conv (Conv2D)  (None, 13, 13, 1024  263168      ['conv4_block35_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block35_3_bn (BatchNorma  (None, 13, 13, 1024  4096       ['conv4_block35_3_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block35_add (Add)        (None, 13, 13, 1024  0           ['conv4_block34_out[0][0]',      \n",
      "                                )                                 'conv4_block35_3_bn[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block35_out (Activation)  (None, 13, 13, 1024  0          ['conv4_block35_add[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block36_1_conv (Conv2D)  (None, 13, 13, 256)  262400      ['conv4_block35_out[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block36_1_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block36_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block36_1_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block36_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block36_2_conv (Conv2D)  (None, 13, 13, 256)  590080      ['conv4_block36_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block36_2_bn (BatchNorma  (None, 13, 13, 256)  1024       ['conv4_block36_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block36_2_relu (Activati  (None, 13, 13, 256)  0          ['conv4_block36_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block36_3_conv (Conv2D)  (None, 13, 13, 1024  263168      ['conv4_block36_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block36_3_bn (BatchNorma  (None, 13, 13, 1024  4096       ['conv4_block36_3_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block36_add (Add)        (None, 13, 13, 1024  0           ['conv4_block35_out[0][0]',      \n",
      "                                )                                 'conv4_block36_3_bn[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block36_out (Activation)  (None, 13, 13, 1024  0          ['conv4_block36_add[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block36_out[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block36_out[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 100352)       0           ['conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 100352)      401408      ['flatten_3[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 100)          10035300    ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 100)          0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 50)           5050        ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 50)           0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 68,812,702\n",
      "Trainable params: 10,241,054\n",
      "Non-trainable params: 58,571,648\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Here we can define which layers can be trainable, plus we can define\n",
    "# the output layer from which we can get the features.\n",
    "trainable_layers = [\"\"]\n",
    "output_layer_name = [\"\"]\n",
    "\n",
    "# Load EfficientNet B7\n",
    "resNet50 = tf.keras.applications.resnet.ResNet50(include_top=False, \n",
    "                                                    classes=num_classes, \n",
    "                                                    weights=configs['pretrain_weights'],\n",
    "                                                    input_shape=input_shape,\n",
    "                                                    input_tensor=input0)\n",
    "\n",
    "feature_extractor = tf.keras.models.Model(inputs=input0, \n",
    "                                            outputs=resNet50.output, \n",
    "                                            name=\"ResNet50_features\")\n",
    "#set the feture extractor layers as non-trainable\n",
    "for idx,layer in enumerate(feature_extractor.layers):\n",
    "    if layer.name in trainable_layers:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "# get the output tensor from a layer of the feature extractor\n",
    "output_extractor = feature_extractor.output\n",
    "#output_extractor = feature_extractor.get_layer(name = output_layer_name).output\n",
    "\n",
    "# flat the output of a Conv layer\n",
    "flatten = Flatten()(output_extractor)\n",
    "flatten_norm = BatchNormalization()(flatten)\n",
    "\n",
    "# add a Dense layer\n",
    "dense2 = Dense(100)(flatten_norm)\n",
    "dense2 = Activation(\"relu\")(dense2)\n",
    "\n",
    "# add the final output layer\n",
    "dense3 = Dense(num_classes)(dense2)\n",
    "dense3 = Activation(\"softmax\")(dense3)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=input0, outputs=dense3, name=\"ResNet50\")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "configs['model_name'] = model.name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNet-L2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here batch size must be <= 8 otherwise you will encounter OOM issues (even on Colab)\n",
    "#\n",
    "# PARAMETERS WITH THE ENTIRE ARCHITECTURE:\n",
    "# - Total params: 502,869,746\n",
    "# - Trainable params: 26,974,750\n",
    "# - Non-trainable params: 475,894,996\n",
    "#\n",
    "# PARAMETERS UNTIL THE 3RD BLOCK: \n",
    "# - Total params: 18,157,050\n",
    "# - Trainable params: 11,005,150\n",
    "# - Non-trainable params: 7,151,900\n",
    "# ===========================================================\n",
    "#\n",
    "# The initialization of the model has been stopped at the 3rd block, \n",
    "# since it will take around 30 minutes for a single epoch if we consider\n",
    "# the whole EfficientNet-L2 architecture.\n",
    "#\n",
    "# ===========================================================\n",
    "#\n",
    "# Epoch 1 = loss: 3.9122 - accuracy: 0.0200 -> Time: 12 min\n",
    "# Epoch 2 = loss: 3.9124 - accuracy: 0.0201 -> Time: 12 min\n",
    "#\n",
    "# This is not good for our testing, but this was done to demonstrate that such big\n",
    "# models can be loaded and trained without problems with our LEGO Dataset. \n",
    "# It is not computationally great, though.\n",
    "    \n",
    "trainable_layers = [\"\"]\n",
    "output_layer_name = \"block3k_project_bn\"\n",
    "\n",
    "efficientNetL2 = efn.EfficientNetL2(weights=\"./efficientnet-l2_noisy-student_notop.h5\", \n",
    "                            input_shape=input_shape, \n",
    "                            include_top=False, \n",
    "                            drop_connect_rate=0)\n",
    "\n",
    "feature_extractor = tf.keras.models.Model(inputs=efficientNetL2.input, \n",
    "                                            outputs=efficientNetL2.output, \n",
    "                                            name=\"EfficientNetL2_features\")\n",
    "\n",
    "# Set the feature extractor layers as non-trainable\n",
    "for idx, layer in enumerate(feature_extractor.layers):\n",
    "    if layer.name in trainable_layers:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "        \n",
    "# get the output tensor from a layer of the feature extractor\n",
    "output_extractor = feature_extractor.get_layer(name = output_layer_name).output\n",
    "#output_extractor = feature_extractor.output\n",
    "\n",
    "# flat the output of a Conv layer\n",
    "flatten = Flatten()(output_extractor) \n",
    "\n",
    "dense2 = Dropout(0.2)(flatten)\n",
    "\n",
    "# add a Dense layer\n",
    "dense2 = Dense(100)(dense2)\n",
    "dense2 = Activation(\"relu\")(dense2)\n",
    "\n",
    "# add the final output layer\n",
    "dense3 = Dense(num_classes)(dense2)\n",
    "dense3 = Activation(\"softmax\")(dense3)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=feature_extractor.input, outputs=dense3, name=\"EfficientNet-L2\")\n",
    "\n",
    "print(F\"Number of trainable parameters: {count_params(model.trainable_weights)}\")\n",
    "print(F\"Number of non trainable parameters: {count_params(model.non_trainable_weights)}\")\n",
    "\n",
    "configs['model_name'] = model.name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEGO Model (Personal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LEGOModel\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 200, 200, 3)]     0         \n",
      "                                                                 \n",
      " Conv2D_1 (Conv2D)           (None, 200, 200, 16)      784       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 200, 200, 16)     64        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " AVG_Pooling_1 (AveragePooli  (None, 100, 100, 16)     0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " Conv2D_2 (Conv2D)           (None, 100, 100, 32)      8224      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 100, 100, 32)     128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " AVG_Pooling_2 (AveragePooli  (None, 50, 50, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " Conv2D_3 (Conv2D)           (None, 50, 50, 64)        32832     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 50, 50, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " AVG_Pooling_3 (AveragePooli  (None, 25, 25, 64)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 40000)             0         \n",
      "                                                                 \n",
      " Dense_Layer_2048 (Dense)    (None, 2048)              81922048  \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 2048)             8192      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2048)              0         \n",
      "                                                                 \n",
      " Dense_Layer_1024 (Dense)    (None, 1024)              2098176   \n",
      "                                                                 \n",
      " Dense_Layer_50_OUT (Dense)  (None, 50)                51250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84,121,954\n",
      "Trainable params: 84,117,634\n",
      "Non-trainable params: 4,320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ---------------------- BLOCK 1  ----------------------\n",
    "# We use a Conv2D layer with a Kernel size of 4x4 and stride (1,1).\n",
    "# We use padding as 'same', meaning that the output size will be the same as the input.\n",
    "# ReLU is the activation function of the Conv2D.\n",
    "x = Conv2D(16, kernel_size=(4, 4), strides=(1, 1), activation='relu', padding='same', name=\"Conv2D_1\")(input0)\n",
    "x = BatchNormalization()(x) # Batch normalization on the Conv2D.\n",
    "# AVG Pooling with a Pool Size of (2, 2). We use padding 'valid', meaning that our output shape will be of: 100 x 100 x 16\n",
    "x = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid', name=\"AVG_Pooling_1\")(x) \n",
    "\n",
    "# ---------------------- BLOCK 2  ----------------------\n",
    "x = Conv2D(32, kernel_size=(4, 4), strides=(1, 1), activation='relu', padding='same', name=\"Conv2D_2\")(x) # 100 x 100 x 32\n",
    "x = BatchNormalization()(x)\n",
    "x = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid', name=\"AVG_Pooling_2\")(x)          # 50 x 50 x 32\n",
    "\n",
    "# ---------------------- BLOCK 3  ----------------------\n",
    "x = Conv2D(64, kernel_size=(4, 4), strides=(1, 1), activation='relu', padding='same', name=\"Conv2D_3\")(x) # 50 x 50 x 64\n",
    "x = BatchNormalization()(x)\n",
    "x = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid', name=\"AVG_Pooling_3\")(x)          # 25 x 25 x 64\n",
    "\n",
    "# ----------------- STARTING DENSE LAYERS  -----------------\n",
    "\n",
    "x = Flatten()(x) # We flatten the previous AveragePooling Layer\n",
    "\n",
    "# We instantiate a Fully Connected Layer (Dense) with 2048 units and ReLU on top.\n",
    "# After that, we simply apply a BatchNormalization() and a Dropout Layer with value 0.2\n",
    "# Dropout rate is very low, otherwise the validation accuracy would be higher than training\n",
    "# (Due to the fact that while in evaluate mode, the Dropout Layer gets de-activated)\n",
    "dense1 = Dense(2048, name=\"Dense_Layer_2048\", activation='relu')(x)    \n",
    "dense1 = BatchNormalization()(dense1)\n",
    "dense1 = Dropout(0.2)(dense1)\n",
    "\n",
    "# We then apply another FC Layer with 1024 units\n",
    "dense2 = Dense(1024, name=\"Dense_Layer_1024\", activation='relu')(dense1)\n",
    "\n",
    "# Lastly, we build the last FC Layer with 50 units (classes)\n",
    "# We then apply a simple SoftMax activation function on top.\n",
    "dense3 = Dense(num_classes, activation=\"softmax\", name=\"Dense_Layer_50_OUT\")(dense2)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=input0, outputs=dense3, name=\"LEGOModel\")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "configs.update([\n",
    "    ('model_name', model.name),\n",
    "    ('pretrain_weights', 'None')\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_epoch = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resuming Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= RESUMING TRAINING =========\n",
    "\n",
    "# Update configs here\n",
    "configRun = [['model_name', 'LEGOModel'], ['epochs', 15]]\n",
    "\n",
    "run, model = resumeTraining(project_name='None', entity_name='None', run_id='None', version='None', configRun=configRun)\n",
    "\n",
    "model.summary()\n",
    "configs = run.config\n",
    "\n",
    "configs['model_name'] = model.name\n",
    "configs['pretrain_weights'] = 'None'\n",
    "configs['init_learning_rate'] = run.config['learning_rate']\n",
    "\n",
    "initial_epoch = configRun['epochs']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New training from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(\n",
    "    project=\"ML - Homework 2\", \n",
    "    entity=\"slimshadys\",\n",
    "    config=configs,\n",
    "    job_type='train',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_scheduler(epoch, lr):\n",
    "    # log the current learning rate onto W&B\n",
    "    if wandb.run is None:\n",
    "        raise wandb.Error(\"You must call wandb.init() before WandbCallback()\")\n",
    "\n",
    "    wandb.log({'learning_rate': lr}, commit=False)\n",
    "    \n",
    "    if epoch < 8:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-configs['lr_decay_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_epochs(epoch,logs):\n",
    "    for file in os.listdir(wandb.run.dir):\n",
    "        if(file.startswith(F\"model-{model.name}-\" + F'{epoch-1:02d}') and file.endswith(\".h5\")):\n",
    "            os.remove(os.path.join(wandb.run.dir, file))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments for the fit() function\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=configs['patience'])\n",
    "deleteEpochs = tf.keras.callbacks.LambdaCallback(on_epoch_begin=delete_epochs)\n",
    "\n",
    "# Define WandbCallback for experiment tracking\n",
    "model_checkpoint = WandbModelCheckpoint(monitor='val_accuracy',\n",
    "    filepath = wandb.run.dir + '\\\\' + F'model-{model.name}' + '-{epoch:02d}.h5',\n",
    "    save_best_only=False,\n",
    "    save_freq='epoch')\n",
    "\n",
    "wandb_callback = WandbCallback(monitor='val_accuracy',\n",
    "                               log_weights=True,\n",
    "                               log_evaluation=True,\n",
    "                               save_model=True,\n",
    "                               validation_steps=5)\n",
    "workers = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config: dict, \n",
    "          callbacks: list,\n",
    "          verbose: int=2):\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    # Arguments for the compile() function\n",
    "    optimizer = optimizers.Adam(learning_rate=config['init_learning_rate'])\n",
    "    wandb.config['optimizer'] = \"adam\"\n",
    "\n",
    "    model.compile(\n",
    "        optimizer = optimizer, \n",
    "        loss = config['loss_fn'], \n",
    "        metrics = config['metrics']\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        h = model.fit(train_loader, epochs=config['epochs'], \n",
    "                      use_multiprocessing = False,\n",
    "                      initial_epoch = initial_epoch, workers=workers, \n",
    "                      verbose=verbose, callbacks=callbacks, \n",
    "                      validation_data=validation_loader)\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_flag': 'LEGODataset', 'batch_size': 32, 'pretrain_weights': 'imagenet', 'epochs': 50, 'init_learning_rate': 0.001, 'lr_decay_rate': 0.1, 'optimizer': 'adam', 'model_name': 'VGG16Edited', 'loss_fn': 'categorical_crossentropy', 'metrics': ['accuracy'], 'patience': 5, 'dataAugmentation': 1}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check configs\n",
    "print(wandb.config)\n",
    "print(\"=================================\")\n",
    "print(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 135s 134ms/step - loss: 0.1429 - accuracy: 0.9621 - val_loss: 0.2982 - val_accuracy: 0.9111 - lr: 2.2371e-05\n",
      "Epoch 47/50\n",
      "1000/1000 [==============================] - 134s 133ms/step - loss: 0.1397 - accuracy: 0.9638 - val_loss: 0.2933 - val_accuracy: 0.9119 - lr: 2.0242e-05\n",
      "Epoch 48/50\n",
      "1000/1000 [==============================] - 133s 132ms/step - loss: 0.1371 - accuracy: 0.9637 - val_loss: 0.2925 - val_accuracy: 0.9130 - lr: 1.8316e-05\n",
      "Epoch 49/50\n",
      "1000/1000 [==============================] - 133s 132ms/step - loss: 0.1404 - accuracy: 0.9630 - val_loss: 0.2939 - val_accuracy: 0.9122 - lr: 1.6573e-05\n",
      "5/5 [==============================] - 1s 123ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 25s 98ms/step - loss: 0.2939 - accuracy: 0.9122\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▃▄▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇██████████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>evaluate/accuracy</td><td>▁</td></tr><tr><td>evaluate/loss</td><td>▁</td></tr><tr><td>learning_rate</td><td>████████▇▆▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>█▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▄▅▆▆▆▆▆▇▇█▇▇██████████████████████████</td></tr><tr><td>val_loss</td><td>█▅▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.96297</td></tr><tr><td>best_epoch</td><td>43</td></tr><tr><td>best_val_accuracy</td><td>0.9135</td></tr><tr><td>epoch</td><td>48</td></tr><tr><td>evaluate/accuracy</td><td>0.91225</td></tr><tr><td>evaluate/loss</td><td>0.29392</td></tr><tr><td>learning_rate</td><td>2e-05</td></tr><tr><td>loss</td><td>0.14043</td></tr><tr><td>val_accuracy</td><td>0.91225</td></tr><tr><td>val_loss</td><td>0.29392</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">leafy-grass-74</strong>: <a href=\"https://wandb.ai/slimshadys/ML%20-%20Homework%202/runs/2dsuvtva\" target=\"_blank\">https://wandb.ai/slimshadys/ML%20-%20Homework%202/runs/2dsuvtva</a><br/>Synced 6 W&B file(s), 3 media file(s), 314 artifact file(s) and 3 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221217_170105-2dsuvtva\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to delete useless artifacts..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully deleted 74 useless artifacts!\n"
     ]
    }
   ],
   "source": [
    "callbacks = [stopping, wandb_callback, lr_callback, model_checkpoint, deleteEpochs]\n",
    "\n",
    "# Train\n",
    "model = train(configs, callbacks, verbose=1)\n",
    "\n",
    "# Evaluate the trained model\n",
    "loss, acc = model.evaluate(validation_loader)\n",
    "wandb.log({'evaluate/accuracy': acc})\n",
    "wandb.log({'evaluate/loss': loss})\n",
    "\n",
    "# Close the W&B run.\n",
    "wandb.finish()\n",
    "deleteArtifacts(run.id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the best model for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95d004348c0c4817beae0022e1cafce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Gianmarco\\Università-Git\\MachineLearning\\test\\Homeworks\\2. Image Classification\\wandb\\run-20221227_123325-2dsuvtva</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href=\"https://wandb.ai/slimshadys/ML%20-%20Homework%202/runs/2dsuvtva\" target=\"_blank\">leafy-grass-74</a></strong> to <a href=\"https://wandb.ai/slimshadys/ML%20-%20Homework%202\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VGG16Edited\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 200, 200, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 200, 200, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 200, 200, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 100, 100, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 100, 100, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 100, 100, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 50, 50, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 50, 50, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 50, 50, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 50, 50, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 25, 25, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 25, 25, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 25, 25, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 25, 25, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 12, 12, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " average_pooling2d_2 (Averag  (None, 1, 1, 512)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               51300     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 50)               200       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 50)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,773,686\n",
      "Trainable params: 2,417,482\n",
      "Non-trainable params: 12,356,204\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27e318c2f27740bebbef61cac8b578a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.96297</td></tr><tr><td>best_epoch</td><td>43</td></tr><tr><td>best_val_accuracy</td><td>0.9135</td></tr><tr><td>epoch</td><td>48</td></tr><tr><td>evaluate/accuracy</td><td>0.91225</td></tr><tr><td>evaluate/loss</td><td>0.29392</td></tr><tr><td>learning_rate</td><td>2e-05</td></tr><tr><td>loss</td><td>0.14043</td></tr><tr><td>val_accuracy</td><td>0.91225</td></tr><tr><td>val_loss</td><td>0.29392</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">leafy-grass-74</strong>: <a href=\"https://wandb.ai/slimshadys/ML%20-%20Homework%202/runs/2dsuvtva\" target=\"_blank\">https://wandb.ai/slimshadys/ML%20-%20Homework%202/runs/2dsuvtva</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221227_123325-2dsuvtva\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VGG16Edited\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 200, 200, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 200, 200, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 200, 200, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 100, 100, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 100, 100, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 100, 100, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 50, 50, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 50, 50, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 50, 50, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 50, 50, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 25, 25, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 25, 25, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 25, 25, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 25, 25, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 12, 12, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " average_pooling2d_2 (Averag  (None, 1, 1, 512)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               51300     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 50)               200       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 50)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,773,686\n",
      "Trainable params: 2,417,482\n",
      "Non-trainable params: 12,356,204\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ========= RETRIEVE THE BEST MODEL FOR EVALUATION =========\n",
    "\n",
    "# Update configs here\n",
    "\n",
    "'Run: leafy-grass-74  |-| Val acc: 0.9135'\n",
    "model = resumeBestModel(project_name='ML - Homework 2', entity_name='slimshadys', run_id='2dsuvtva')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.294674\n",
      "Test accuracy: 0.913250\n"
     ]
    }
   ],
   "source": [
    "workers = multiprocessing.cpu_count()\n",
    "\n",
    "loss, acc = model.evaluate(validation_loader, workers=workers, verbose=2)\n",
    "print('Test loss: %f' %loss)\n",
    "print('Test accuracy: %f' %acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 131s 524ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       14719     0.9146    0.9375    0.9259       160\n",
      "       15672     0.9816    1.0000    0.9907       160\n",
      "       18654     0.9938    1.0000    0.9969       160\n",
      "        2357     0.8555    0.9250    0.8889       160\n",
      "        2420     0.9255    0.9313    0.9283       160\n",
      "        2780     0.9938    1.0000    0.9969       160\n",
      "       27925     0.9930    0.8875    0.9373       160\n",
      "        3001     0.8721    0.9375    0.9036       160\n",
      "        3002     0.8712    0.8875    0.8793       160\n",
      "        3003     0.7943    0.8688    0.8299       160\n",
      "        3004     0.8526    0.8313    0.8418       160\n",
      "        3005     0.9176    0.9750    0.9455       160\n",
      "        3010     0.9189    0.8500    0.8831       160\n",
      "        3020     0.9383    0.9500    0.9441       160\n",
      "        3021     0.9245    0.9187    0.9216       160\n",
      "        3022     0.8431    0.8063    0.8243       160\n",
      "        3023     0.9281    0.8875    0.9073       160\n",
      "        3024     0.8579    0.9812    0.9155       160\n",
      "        3037     0.9071    0.7937    0.8467       160\n",
      "        3038     0.8155    0.8562    0.8354       160\n",
      "        3039     0.7588    0.8063    0.7818       160\n",
      "        3040     0.8800    0.8250    0.8516       160\n",
      "        3045     0.9058    0.7812    0.8389       160\n",
      "        3046     0.7605    0.7937    0.7768       160\n",
      "        3062     1.0000    1.0000    1.0000       160\n",
      "        3063     0.9869    0.9437    0.9649       160\n",
      "        3068     0.9366    0.8313    0.8808       160\n",
      "        3069     0.8140    0.8750    0.8434       160\n",
      "        3070     0.8857    0.9688    0.9254       160\n",
      "        3298     0.9110    0.8313    0.8693       160\n",
      "       33909     0.8046    0.8750    0.8383       160\n",
      "        3622     0.8580    0.9062    0.8815       160\n",
      "        3623     0.9313    0.9313    0.9313       160\n",
      "        3659     0.9542    0.9125    0.9329       160\n",
      "        3675     0.9539    0.9062    0.9295       160\n",
      "        3700     0.8848    0.9125    0.8985       160\n",
      "        3794     0.9299    0.9125    0.9211       160\n",
      "        4150     0.9938    0.9938    0.9938       160\n",
      "       41677     0.9873    0.9750    0.9811       160\n",
      "       41678     1.0000    0.9938    0.9969       160\n",
      "        4274     1.0000    1.0000    1.0000       160\n",
      "        4286     0.8650    0.8812    0.8731       160\n",
      "       43093     1.0000    0.9938    0.9969       160\n",
      "       43857     0.9936    0.9750    0.9842       160\n",
      "        4490     0.9024    0.9250    0.9136       160\n",
      "       54200     0.9367    0.9250    0.9308       160\n",
      "        6143     0.9877    1.0000    0.9938       160\n",
      "        6632     0.9812    0.9812    0.9812       160\n",
      "       85984     0.9524    0.8750    0.9121       160\n",
      "       99301     0.8951    0.9062    0.9006       160\n",
      "\n",
      "    accuracy                         0.9133      8000\n",
      "   macro avg     0.9150    0.9132    0.9133      8000\n",
      "weighted avg     0.9150    0.9133    0.9133      8000\n",
      "\n",
      "============================================\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(validation_loader, workers=workers, verbose=1)\n",
    "\n",
    "Ypred = np.argmax(preds, axis=1)\n",
    "Ytest = validation_loader.classes\n",
    "\n",
    "print(classification_report(Ytest, Ypred, labels=None, target_names=classnames, digits=4))\n",
    "\n",
    "print(\"============================================\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Confusion matrix')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x2000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(Ytest, Ypred, labels=range(50))\n",
    "# plot confusion matrix as an image\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "plt.imshow(cm)\n",
    "plt.colorbar()\n",
    "plt.yticks(range(0, 50, 1))\n",
    "plt.xticks(range(0, 50, 1))\n",
    "plt.xlabel(\"Predicted labels\")\n",
    "plt.ylabel(\"True labels\")\n",
    "plt.title(\"Confusion matrix\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix with error percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True                 Predicted         \terrors \terr % \n",
      "------------------------------------------------------------------\n",
      "3046             ->  3003              \t22 \t0.28 % \n",
      "3045             ->  3039              \t22 \t0.28 % \n",
      "3022             ->  33909             \t21 \t0.26 % \n",
      "3039             ->  3046              \t16 \t0.20 % \n",
      "3037             ->  3038              \t13 \t0.16 % \n",
      "3068             ->  3069              \t12 \t0.15 % \n",
      "3010             ->  3622              \t12 \t0.15 % \n",
      "3003             ->  3046              \t11 \t0.14 % \n",
      "33909            ->  3022              \t11 \t0.14 % \n",
      "3069             ->  3070              \t11 \t0.14 % \n",
      "3004             ->  3700              \t10 \t0.12 % \n",
      "3794             ->  3024              \t10 \t0.12 % \n",
      "3068             ->  33909             \t10 \t0.12 % \n",
      "85984            ->  54200             \t9 \t0.11 % \n",
      "3659             ->  4490              \t9 \t0.11 % \n",
      "3298             ->  4286              \t8 \t0.10 % \n",
      "3700             ->  3004              \t8 \t0.10 % \n",
      "3003             ->  2357              \t8 \t0.10 % \n",
      "85984            ->  3069              \t8 \t0.10 % \n",
      "3675             ->  99301             \t7 \t0.09 % \n",
      "3021             ->  3020              \t7 \t0.09 % \n",
      "4286             ->  3040              \t7 \t0.09 % \n",
      "3002             ->  3001              \t7 \t0.09 % \n",
      "3298             ->  3038              \t7 \t0.09 % \n",
      "3037             ->  3001              \t7 \t0.09 % \n",
      "3002             ->  3003              \t6 \t0.07 % \n",
      "3040             ->  4286              \t6 \t0.07 % \n",
      "3046             ->  2357              \t6 \t0.07 % \n",
      "3039             ->  3038              \t5 \t0.06 % \n",
      "3040             ->  3039              \t5 \t0.06 % \n",
      "3045             ->  3040              \t5 \t0.06 % \n",
      "3675             ->  3298              \t5 \t0.06 % \n",
      "54200            ->  3024              \t5 \t0.06 % \n",
      "99301            ->  3002              \t5 \t0.06 % \n",
      "3023             ->  3794              \t5 \t0.06 % \n",
      "3004             ->  3005              \t5 \t0.06 % \n",
      "14719            ->  2420              \t5 \t0.06 % \n",
      "3001             ->  3002              \t5 \t0.06 % \n",
      "2420             ->  14719             \t5 \t0.06 % \n",
      "2357             ->  3046              \t5 \t0.06 % \n",
      "27925            ->  14719             \t5 \t0.06 % \n",
      "4490             ->  3659              \t4 \t0.05 % \n",
      "3037             ->  3010              \t4 \t0.05 % \n",
      "3038             ->  3002              \t4 \t0.05 % \n",
      "3038             ->  3037              \t4 \t0.05 % \n",
      "3045             ->  4286              \t4 \t0.05 % \n",
      "27925            ->  3070              \t4 \t0.05 % \n",
      "3046             ->  3039              \t4 \t0.05 % \n",
      "3023             ->  3024              \t4 \t0.05 % \n",
      "3063             ->  2357              \t4 \t0.05 % \n",
      "2357             ->  3003              \t4 \t0.05 % \n",
      "3069             ->  3068              \t4 \t0.05 % \n",
      "3070             ->  3024              \t4 \t0.05 % \n",
      "3622             ->  3010              \t4 \t0.05 % \n",
      "27925            ->  3069              \t4 \t0.05 % \n",
      "4490             ->  3700              \t4 \t0.05 % \n",
      "3622             ->  4490              \t4 \t0.05 % \n",
      "99301            ->  3001              \t4 \t0.05 % \n",
      "3020             ->  3021              \t3 \t0.04 % \n",
      "3038             ->  3039              \t3 \t0.04 % \n",
      "3038             ->  3045              \t3 \t0.04 % \n",
      "3038             ->  3622              \t3 \t0.04 % \n",
      "3020             ->  3001              \t3 \t0.04 % \n",
      "14719            ->  3069              \t3 \t0.04 % \n",
      "3038             ->  99301             \t3 \t0.04 % \n",
      "3004             ->  3622              \t3 \t0.04 % \n",
      "3023             ->  3623              \t3 \t0.04 % \n",
      "3700             ->  3005              \t3 \t0.04 % \n",
      "3037             ->  99301             \t3 \t0.04 % \n",
      "3040             ->  3700              \t3 \t0.04 % \n",
      "3010             ->  3037              \t3 \t0.04 % \n",
      "3298             ->  3046              \t3 \t0.04 % \n",
      "3623             ->  3022              \t3 \t0.04 % \n",
      "4286             ->  3045              \t3 \t0.04 % \n",
      "3659             ->  3004              \t3 \t0.04 % \n",
      "54200            ->  3070              \t3 \t0.04 % \n",
      "3298             ->  3039              \t3 \t0.04 % \n",
      "3022             ->  2420              \t3 \t0.04 % \n",
      "33909            ->  3023              \t3 \t0.04 % \n",
      "3022             ->  3021              \t3 \t0.04 % \n",
      "3039             ->  3045              \t3 \t0.04 % \n",
      "41677            ->  6632              \t3 \t0.04 % \n",
      "3623             ->  3021              \t3 \t0.04 % \n",
      "27925            ->  3794              \t2 \t0.03 % \n",
      "3045             ->  3038              \t2 \t0.03 % \n",
      "3045             ->  3298              \t2 \t0.03 % \n",
      "3010             ->  3002              \t2 \t0.03 % \n",
      "3040             ->  3622              \t2 \t0.03 % \n",
      "99301            ->  3038              \t2 \t0.03 % \n",
      "27925            ->  3068              \t2 \t0.03 % \n",
      "3005             ->  3004              \t2 \t0.03 % \n",
      "3004             ->  3039              \t2 \t0.03 % \n",
      "3622             ->  3004              \t2 \t0.03 % \n",
      "3004             ->  3040              \t2 \t0.03 % \n",
      "2420             ->  3022              \t2 \t0.03 % \n",
      "3298             ->  3675              \t2 \t0.03 % \n",
      "3675             ->  4286              \t2 \t0.03 % \n",
      "3005             ->  3024              \t2 \t0.03 % \n",
      "99301            ->  3037              \t2 \t0.03 % \n",
      "3069             ->  85984             \t2 \t0.03 % \n",
      "3004             ->  3003              \t2 \t0.03 % \n",
      "3068             ->  3022              \t2 \t0.03 % \n",
      "3068             ->  14719             \t2 \t0.03 % \n",
      "3063             ->  6143              \t2 \t0.03 % \n",
      "3063             ->  3004              \t2 \t0.03 % \n",
      "3700             ->  3040              \t2 \t0.03 % \n",
      "3040             ->  3045              \t2 \t0.03 % \n",
      "99301            ->  3675              \t2 \t0.03 % \n",
      "3010             ->  3659              \t2 \t0.03 % \n",
      "54200            ->  3005              \t2 \t0.03 % \n",
      "3002             ->  3010              \t2 \t0.03 % \n",
      "3038             ->  3298              \t2 \t0.03 % \n",
      "43857            ->  85984             \t2 \t0.03 % \n",
      "3021             ->  3022              \t2 \t0.03 % \n",
      "3039             ->  2357              \t2 \t0.03 % \n",
      "3022             ->  3623              \t2 \t0.03 % \n",
      "3037             ->  3675              \t2 \t0.03 % \n",
      "3001             ->  99301             \t2 \t0.03 % \n",
      "6632             ->  41677             \t2 \t0.03 % \n",
      "4286             ->  3298              \t2 \t0.03 % \n",
      "3040             ->  3005              \t2 \t0.03 % \n",
      "3040             ->  15672             \t2 \t0.03 % \n",
      "3021             ->  3002              \t2 \t0.03 % \n",
      "3023             ->  3022              \t2 \t0.03 % \n",
      "3020             ->  3022              \t2 \t0.03 % \n",
      "3023             ->  2420              \t2 \t0.03 % \n",
      "3037             ->  3045              \t2 \t0.03 % \n",
      "2357             ->  3622              \t1 \t0.01 % \n",
      "2357             ->  2420              \t1 \t0.01 % \n",
      "4286             ->  3038              \t1 \t0.01 % \n",
      "2420             ->  2357              \t1 \t0.01 % \n",
      "6632             ->  54200             \t1 \t0.01 % \n",
      "54200            ->  3069              \t1 \t0.01 % \n",
      "3659             ->  2357              \t1 \t0.01 % \n",
      "3623             ->  4490              \t1 \t0.01 % \n",
      "3623             ->  3794              \t1 \t0.01 % \n",
      "3623             ->  3622              \t1 \t0.01 % \n",
      "3623             ->  3024              \t1 \t0.01 % \n",
      "54200            ->  85984             \t1 \t0.01 % \n",
      "3623             ->  3023              \t1 \t0.01 % \n",
      "3675             ->  3020              \t1 \t0.01 % \n",
      "3659             ->  3010              \t1 \t0.01 % \n",
      "4490             ->  3010              \t1 \t0.01 % \n",
      "4490             ->  3622              \t1 \t0.01 % \n",
      "4286             ->  15672             \t1 \t0.01 % \n",
      "4286             ->  14719             \t1 \t0.01 % \n",
      "4286             ->  3039              \t1 \t0.01 % \n",
      "2357             ->  3002              \t1 \t0.01 % \n",
      "4286             ->  3046              \t1 \t0.01 % \n",
      "4286             ->  3623              \t1 \t0.01 % \n",
      "41677            ->  3070              \t1 \t0.01 % \n",
      "4286             ->  3794              \t1 \t0.01 % \n",
      "4150             ->  3069              \t1 \t0.01 % \n",
      "43093            ->  2780              \t1 \t0.01 % \n",
      "14719            ->  3794              \t1 \t0.01 % \n",
      "85984            ->  3623              \t1 \t0.01 % \n",
      "3794             ->  3700              \t1 \t0.01 % \n",
      "85984            ->  3068              \t1 \t0.01 % \n",
      "3794             ->  3069              \t1 \t0.01 % \n",
      "43857            ->  18654             \t1 \t0.01 % \n",
      "43857            ->  3069              \t1 \t0.01 % \n",
      "85984            ->  3023              \t1 \t0.01 % \n",
      "4490             ->  3004              \t1 \t0.01 % \n",
      "4490             ->  3005              \t1 \t0.01 % \n",
      "3794             ->  3023              \t1 \t0.01 % \n",
      "3794             ->  3004              \t1 \t0.01 % \n",
      "3700             ->  4490              \t1 \t0.01 % \n",
      "14719            ->  3068              \t1 \t0.01 % \n",
      "41678            ->  3063              \t1 \t0.01 % \n",
      "3003             ->  3063              \t1 \t0.01 % \n",
      "3622             ->  3623              \t1 \t0.01 % \n",
      "3001             ->  3020              \t1 \t0.01 % \n",
      "3039             ->  3037              \t1 \t0.01 % \n",
      "3039             ->  3004              \t1 \t0.01 % \n",
      "3038             ->  3675              \t1 \t0.01 % \n",
      "3037             ->  3040              \t1 \t0.01 % \n",
      "3037             ->  3039              \t1 \t0.01 % \n",
      "3001             ->  3037              \t1 \t0.01 % \n",
      "3024             ->  3623              \t1 \t0.01 % \n",
      "3024             ->  3070              \t1 \t0.01 % \n",
      "3024             ->  3023              \t1 \t0.01 % \n",
      "3002             ->  2357              \t1 \t0.01 % \n",
      "3023             ->  33909             \t1 \t0.01 % \n",
      "3023             ->  3004              \t1 \t0.01 % \n",
      "3039             ->  3040              \t1 \t0.01 % \n",
      "3022             ->  3023              \t1 \t0.01 % \n",
      "3021             ->  3623              \t1 \t0.01 % \n",
      "3021             ->  3023              \t1 \t0.01 % \n",
      "3002             ->  3021              \t1 \t0.01 % \n",
      "3010             ->  99301             \t1 \t0.01 % \n",
      "3010             ->  4286              \t1 \t0.01 % \n",
      "3002             ->  3622              \t1 \t0.01 % \n",
      "3010             ->  3020              \t1 \t0.01 % \n",
      "3010             ->  3005              \t1 \t0.01 % \n",
      "3010             ->  3001              \t1 \t0.01 % \n",
      "3003             ->  3002              \t1 \t0.01 % \n",
      "3004             ->  33909             \t1 \t0.01 % \n",
      "3004             ->  3298              \t1 \t0.01 % \n",
      "3004             ->  3046              \t1 \t0.01 % \n",
      "3022             ->  3003              \t1 \t0.01 % \n",
      "3039             ->  3298              \t1 \t0.01 % \n",
      "3039             ->  4286              \t1 \t0.01 % \n",
      "3040             ->  3004              \t1 \t0.01 % \n",
      "3622             ->  3046              \t1 \t0.01 % \n",
      "3622             ->  3003              \t1 \t0.01 % \n",
      "3622             ->  3002              \t1 \t0.01 % \n",
      "33909            ->  85984             \t1 \t0.01 % \n",
      "33909            ->  3794              \t1 \t0.01 % \n",
      "33909            ->  3623              \t1 \t0.01 % \n",
      "33909            ->  3068              \t1 \t0.01 % \n",
      "2420             ->  3021              \t1 \t0.01 % \n",
      "33909            ->  3021              \t1 \t0.01 % \n",
      "33909            ->  2420              \t1 \t0.01 % \n",
      "3298             ->  99301             \t1 \t0.01 % \n",
      "2420             ->  3023              \t1 \t0.01 % \n",
      "3298             ->  3037              \t1 \t0.01 % \n",
      "3298             ->  3004              \t1 \t0.01 % \n",
      "3298             ->  2357              \t1 \t0.01 % \n",
      "3070             ->  3069              \t1 \t0.01 % \n",
      "3069             ->  43857             \t1 \t0.01 % \n",
      "2420             ->  33909             \t1 \t0.01 % \n",
      "3069             ->  27925             \t1 \t0.01 % \n",
      "3069             ->  14719             \t1 \t0.01 % \n",
      "3063             ->  3046              \t1 \t0.01 % \n",
      "3046             ->  3038              \t1 \t0.01 % \n",
      "27925            ->  4150              \t1 \t0.01 % \n",
      "3040             ->  4490              \t1 \t0.01 % \n",
      "3040             ->  3659              \t1 \t0.01 % \n",
      "3040             ->  3046              \t1 \t0.01 % \n",
      "3001             ->  2357              \t1 \t0.01 % \n",
      "3040             ->  3037              \t1 \t0.01 % \n",
      "3040             ->  3023              \t1 \t0.01 % \n",
      "3622             ->  3700              \t1 \t0.01 % \n",
      "3068             ->  85984             \t1 \t0.01 % \n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(Ytest, Ypred)\n",
    "\n",
    "conf = [] # data structure for confusions: list of (i,j,cm[i][j])\n",
    "for i in range(0,cm.shape[0]):\n",
    "  for j in range(0,cm.shape[1]):\n",
    "    if (i!=j and cm[i][j]>0):\n",
    "      conf.append([i,j,cm[i][j]])\n",
    "\n",
    "col=2\n",
    "conf = np.array(conf)\n",
    "conf = conf[np.argsort(-conf[:,col])]  # decreasing order by 3-rd column (i.e., cm[i][j])\n",
    "\n",
    "print('%-16s     %-16s  \\t%s \\t%s ' %('True','Predicted','errors','err %'))\n",
    "print('------------------------------------------------------------------')\n",
    "for k in conf:\n",
    "  print('%-16s ->  %-16s  \\t%d \\t%.2f %% ' %(classnames[k[0]],classnames[k[1]],k[2],k[2]*100.0/validation_loader.n))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0245dcb33ee754f1ac52eeb37726094d614f792ee661c1411187169ef218bd3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

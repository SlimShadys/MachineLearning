{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-o2cEpeQZjs"
      },
      "source": [
        "# Machine Learning - Exercise 3\n",
        "# SMS SPAM classification\n",
        "\n",
        "To perform the experiments on the SMSSpamCollection dataset you need to set-up your Colab such that it is able to load the desired data. To achieve this, you need to perform the following actions:\n",
        "\n",
        "*   download the dataset available at this [link](https://drive.google.com/a/diag.uniroma1.it/file/d/17YZemn1MidhFA0-wenfVolZAwclLRUXM/view)\n",
        "*   copy the dataset in a folder of your personal Drive\n",
        "*   mount your Google Drive (more details will follow)\n",
        "*   set the correct path for loading the dataset (more details will follow)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z62YJE78EcK9"
      },
      "source": [
        "## Import needed libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJXZGno8QYOn",
        "outputId": "9821411e-e2e4-4be4-e1b2-fc0894b6a346"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import *\n",
        "from sklearn.naive_bayes import *\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "print('Libraries imported.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dnm5HakC6dO0"
      },
      "source": [
        "## Load data\n",
        "\n",
        "Mount Google Drive by following the instructions given at the provided link"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqhr4vhcRD39",
        "outputId": "a7c93717-4357-4669-cd9f-8edd9cbc3083"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otk6cVVo6mR8"
      },
      "source": [
        "To load the file set the correct path of the dataset located in your drive. Once mounted, your drive works like a Linux system, so you can check folders etc... running commands like `ls` or `cd` preceded by `%`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvPjvjXGQ0sw",
        "outputId": "cf4e5641-d022-4282-efbe-2703293d9d94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File loaded: 5572 samples.\n"
          ]
        }
      ],
      "source": [
        "# example path of dataset copied in My Drive folder: /content/drive/My Drive/SMSSpamCollection'\n",
        "filename = 'C:/Users/Gianmarco/Universit√†-Git/MachineLearning/test/Datasets/SMSSpamCollection'\n",
        "db = pd.read_csv(filename, sep='\\t', header=None, names=['label', 'text'])\n",
        "print('File loaded: %d samples.' %(len(db.label)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns_oBwUo64tF"
      },
      "source": [
        "Show a random sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhl2FLCKSUmo",
        "outputId": "fb7d2c28-e4f7-4ec3-a2a2-287bfc779bd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- ID: 1211\n",
            "- Label: ham\n",
            "- Text: Guessin you ain't gonna be here before 9?\n"
          ]
        }
      ],
      "source": [
        "id = random.randrange(0,len(db.label))\n",
        "print('- ID: %d\\n- Label: %s\\n- Text: %s' %(id,db.label[id],db.text[id]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uBD7RsJ7bzB"
      },
      "source": [
        "## Choose vectorizer\n",
        "\n",
        "Compute vectorizer terms for all messages. More info:\n",
        "\n",
        "\n",
        "\n",
        "*   [Hashing](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html)\n",
        "*   [Count](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)\n",
        "*   [Tfid](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKWEucDKWnDY",
        "outputId": "13d30405-0c46-43ef-e752-ce310f6556e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X (Sparse Matrix) shape: (5572, 8444)\n",
            "Y (GT Labels) shape: (5572,)\n"
          ]
        }
      ],
      "source": [
        "vectorizer_type = \"count\" # \"hashing\", \"count\" or \"tfid\"\n",
        "\n",
        "if vectorizer_type == \"hashing\":\n",
        "  vectorizer = HashingVectorizer(stop_words='english') # multivariate\n",
        "elif vectorizer_type == \"count\":\n",
        "  vectorizer = CountVectorizer(stop_words='english') # multinomial\n",
        "elif vectorizer_type == \"tfid\":\n",
        "  vectorizer = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "X_all = vectorizer.fit_transform(db.text)\n",
        "y_all = db.label\n",
        "\n",
        "print(F\"X (Sparse Matrix) shape: {X_all.shape}\")\n",
        "print(F\"Y (GT Labels) shape: {y_all.shape}\")\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7oczFvA7nXb"
      },
      "source": [
        "## Split data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Yw3Fz1NSu01",
        "outputId": "f5337cd5-7afa-4671-d8b5-958d639ff8af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 4457 - Test: 1115\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, \n",
        "          test_size=0.2, random_state=16)\n",
        "\n",
        "print(\"Train: %d - Test: %d\" %(X_train.shape[0],X_test.shape[0]))\n",
        "\n",
        "#id = random.randrange(0,X_train.shape[0])\n",
        "#print('%d ' %(id))\n",
        "#print('%d %s %s' %(id,str(y_train[id]),str(X_train[id])))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y66oz8ep57xg"
      },
      "source": [
        "## Create and fit Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nk4BBWhpUrQO",
        "outputId": "3cfc13d0-8bc4-475e-d062-06abb82220bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Multinomial Model created\n"
          ]
        }
      ],
      "source": [
        "model_type = \"multinomial\" # \"bernoulli\" or \"multinomial\"\n",
        "\n",
        "if model_type == \"bernoulli\":\n",
        "  model = BernoulliNB().fit(X_train, y_train)\n",
        "  print('Bernoulli Model created')\n",
        "elif model_type == \"multinomial\":\n",
        "  model = MultinomialNB().fit(X_train, y_train)\n",
        "  print('Multinomial Model created')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VBrexa46DmE"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2dR-PQtaiJC",
        "outputId": "c49e2f03-dca3-4bdc-b1a3-1b309c7c1f7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[962   9]\n",
            " [ 10 134]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      0.99      0.99       971\n",
            "        spam       0.94      0.93      0.93       144\n",
            "\n",
            "    accuracy                           0.98      1115\n",
            "   macro avg       0.96      0.96      0.96      1115\n",
            "weighted avg       0.98      0.98      0.98      1115\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaiH-mlO6I-9"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AD7Le-lVX9M8",
        "outputId": "8a13f765-f74a-4097-bbf9-a37f424ef4f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Hello, did you solve ML exercise?'] has been classified as:  ['ham']\n",
            "['You won $1,000! Call now 1-800-1234567'] has been classified as:  ['spam']\n"
          ]
        }
      ],
      "source": [
        "smsnew1 = np.array(['Hello, did you solve ML exercise?'])\n",
        "# We ask our model to transform our previous SMS into a 1x8444 sparse Matrix\n",
        "# Then we predict based on the previous transformation\n",
        "xnew1 = vectorizer.transform(smsnew1)\n",
        "ynew1 = model.predict(xnew1) \n",
        "print('%s has been classified as:  %s' %(smsnew1,ynew1))\n",
        "\n",
        "# Same goes here.\n",
        "smsnew2 = np.array(['You won $1,000! Call now 1-800-1234567'])\n",
        "xnew2 = vectorizer.transform(smsnew2)\n",
        "ynew2 = model.predict(xnew2)\n",
        "print('%s has been classified as:  %s' %(smsnew2,ynew2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjYkT9M_N5Wb"
      },
      "source": [
        "## Home Exercises\n",
        "\n",
        "**Question 1**\n",
        "\n",
        "Design and implement an evaluation procedure to assess and compare the performance of the three vectorizers and the two models proposed above.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions for the two models Bernoulli / Multinomial with the three vectorizers.\n",
            "\n",
            "         Model Vectorizer  Accuracy        \n",
            "0    Bernoulli    Hashing  0.860987        \n",
            "1    Bernoulli      Count  0.973991        \n",
            "2    Bernoulli       TFID  0.974888        \n",
            "3  Multinomial    Hashing  0.000000        \n",
            "4  Multinomial      Count  0.981166  [BEST]\n",
            "5  Multinomial       TFID  0.970404        \n"
          ]
        }
      ],
      "source": [
        "def generatePredictions(model, vectorizerName):\n",
        "\n",
        "    # Choose the appropiate Vectorizer\n",
        "    if vectorizerName == \"hashing\":\n",
        "        vectorizer = HashingVectorizer(stop_words='english') # multivariate\n",
        "    elif vectorizerName == \"count\":\n",
        "        vectorizer = CountVectorizer(stop_words='english') # multinomial\n",
        "    elif vectorizerName == \"tfid\":\n",
        "        vectorizer = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "    X_all = vectorizer.fit_transform(db.text)\n",
        "    y_all = db.label\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, \n",
        "            test_size=0.2, random_state=random.seed(None))\n",
        "\n",
        "    # We fit the model first, letting it find a solution.\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # X_test contains the inputs reserved for testing purposes.\n",
        "    # This was done above at cell n.9.\n",
        "    y_pred = model.predict(X_test).reshape(-1, 1)\n",
        "    \n",
        "    acc = accuracy_score(y_pred, y_test)\n",
        "    \n",
        "    return acc\n",
        "\n",
        "df = pd.DataFrame({'Model': [\"Bernoulli\", \"Bernoulli\", \"Bernoulli\", \"Multinomial\", \"Multinomial\", \"Multinomial\"], \n",
        "                    'Vectorizer': [\"Hashing\",\"Count\",\"TFID\", \"Hashing\",\"Count\",\"TFID\"],\n",
        "                     'Accuracy': [0,0,0,0,0,0],\n",
        "                     '': [\"\",\"\",\"\",\"\",\"\",\"\"]\n",
        "                    })\n",
        "\n",
        "print(\"Predictions for the two models Bernoulli / Multinomial with the three vectorizers.\")\n",
        "\n",
        "\n",
        "### ==== BERNOULLI / Hashing - Count - TFID ==== ###\n",
        "modelBernoulli = BernoulliNB()\n",
        "\n",
        "df.iat[0, 2] = generatePredictions(modelBernoulli, \"hashing\")\n",
        "df.iat[1, 2] = generatePredictions(modelBernoulli, \"count\")\n",
        "df.iat[2, 2] = generatePredictions(modelBernoulli, \"tfid\")\n",
        "\n",
        "### ========= Multinomial / Hashing - Count - TFID ======== ###\n",
        "modelMultinomial = MultinomialNB()\n",
        "\n",
        "# Using HashingVectorizer on a Multinomial model, results in error.\n",
        "# This is why Multinomial/Hashing has the same accuracy as Multinomial/Count.\n",
        "#df.iat[3, 2]  = generatePredictions(modelMultinomial, \"hashing\")\n",
        "df.iat[4, 2]  = generatePredictions(modelMultinomial, \"count\")\n",
        "df.iat[5, 2]  = generatePredictions(modelMultinomial, \"tfid\")\n",
        "\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "max_value = df[\"Accuracy\"].max()\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    modelName = row['Model']\n",
        "    vectorType = row['Vectorizer']\n",
        "    accuracy = row['Accuracy']\n",
        "\n",
        "    if(max_value == accuracy):\n",
        "        df.iat[index, 3] = \"[BEST]\"\n",
        "\n",
        "print(F\"\\n{df}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "0245dcb33ee754f1ac52eeb37726094d614f792ee661c1411187169ef218bd3b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
